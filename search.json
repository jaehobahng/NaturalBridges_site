[
  {
    "objectID": "Overview_Analysis.html",
    "href": "Overview_Analysis.html",
    "title": "Dataset Analysis",
    "section": "",
    "text": "Before we dive into scenarios, lets conduct a simple comparison on the overall trend of RCP 4.5 and 8.5. What variables influence annual temperature the most when grouped into two RCP scenarios as a whole?\nMethodology\nWe will be using scatterplots and pearson correlation and RMSE to find similarities and differences between the two RCP scenarios.\n\n\nImport module / Set options and theme\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy.stats import ttest_rel\nfrom statsmodels.stats.weightstats import ttest_ind\nimport numpy as np\nimport pingouin as pg\nfrom scipy.stats import zscore\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)"
  },
  {
    "objectID": "Overview_Analysis.html#scatterplot",
    "href": "Overview_Analysis.html#scatterplot",
    "title": "Dataset Analysis",
    "section": "Scatterplot",
    "text": "Scatterplot\nWith a basic scatterplot, we can see basic correlations of how each numerical variable correlates to either the annual temperature or the annual percipitation. Since RCP 8.5 and RCP 4.5 have different predictions, two plots were used for each scenario.\nFirstly, without an additional feature, we can see that the more percipitation, the lower the annual temperature because we can easily draw a line with a negative slope through the scaterred plots.\n\n\n4.5 vs 8.5 scatterplot\n# Assuming df_con is your DataFrame and is already loaded\n# List of columns to use for coloring\ntest = df_con.iloc[:,list(range(1, 3))+ [4,6] + list(range(8, len(df_con.columns)-1))]\ncolor_columns = list(test.columns)\nrcp_values = test['RCP'].unique()\n\nsubplot_titles = [f'RCP {rcp}' for rcp in rcp_values]\n\n# Create figure with subplots for each RCP value\nfig = make_subplots(rows=1, cols=len(rcp_values), shared_yaxes=True, subplot_titles=subplot_titles, horizontal_spacing=0.15)\n\n# Add a scatter trace for each color column and each RCP value\nfor i, col in enumerate(color_columns):\n    for j, rcp in enumerate(rcp_values):\n        fig.add_trace(\n            go.Scatter(\n                x=test[(test['year'].isin(range(2060, 2100))) & (test['RCP'] == rcp)]['PPT_Annual'],\n                y=test[(test['year'].isin(range(2060, 2100))) & (test['RCP'] == rcp)]['T_Annual'],\n                mode='markers',\n                marker=dict(\n                    color=test[(test['year'].isin(range(2060, 2100))) & (test['RCP'] == rcp)][col],\n                    colorbar=dict(\n                        # title='Scale',\n                                  tickmode='array',\n                                  tickvals=[round(i,2) for i in np.linspace(start=round(min(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),stop=round(max(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),num=5)],\n                                  ticktext=[round(i,2) for i in np.linspace(start=round(min(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),stop=round(max(test[(test['year'].isin(range(2060, 2100)) & (test['RCP'] == rcp))][col]),2),num=5)],\n                                  y=0.5,\n                                  x= 0.43 + (j*0.58)\n                                  ),\n                                  colorscale='rdpu'\n                ),\n                name=col,\n                visible=True if i == 0 else False,\n                hovertemplate=(\n                    f\"&lt;b&gt;{col}&lt;/b&gt;&lt;br&gt;\"\n                    \"Precipitation: %{x}&lt;br&gt;\"\n                    \"Temperature: %{y}&lt;br&gt;\"\n                    \"RCP: \" + str(rcp) + \"&lt;br&gt;\"\n                    \"Value: %{marker.color}&lt;br&gt;\"\n                    \"&lt;extra&gt;&lt;/extra&gt;\"\n                  )  # This hides the secondary box with trace info  # Only the first trace is visible initially\n            ),\n            row=1, col=j+1\n        )\n\n# Updating the layout to add the title\nfig.update_layout(\n    title={\n        'text': '&lt;b&gt;Annual Precipitation vs Temperature by RCP Scenarios&lt;/b&gt;',\n        'x': 0.5,\n        'y': 0.97,\n        'xanchor': 'center'\n    },\n    # title_font=dict(size=20),\n    showlegend=False  # Hide legend since we are using colorbars\n)\n\n# Adding dropdown filter to change visible trace\ndropdown_buttons = [\n    {\n        'label': col,\n        'method': 'update',\n        'args': [\n            {\n                'visible': [col == color_column for color_column in color_columns for _ in rcp_values]\n            },\n            {\n                'title': {'text': f'&lt;b&gt;Annual Precipitation vs Temperature by {col}&lt;/b&gt;', 'x':0.5, 'y':0.97},\n                'marker': {'colorbar': {'title': 'Scale'}}\n            }\n        ]\n    }\n    for col in color_columns\n]\n\nfig.update_layout(\n    updatemenus=[\n        {\n            'buttons': dropdown_buttons,\n            'direction': 'down',\n            'showactive': True,\n            'x': 0.5,\n            'xanchor': 'center',\n            'y': 1.19,\n            'yanchor': 'top'\n        }\n    ]\n)\n\nfig.update_xaxes(title_text=\"Annual Precipitation\", row=1, col=1)\nfig.update_yaxes(title_text=\"Annual Temperature\", row=1, col=1)\nfig.update_xaxes(title_text=\"Annual Precipitation\", row=1, col=2)\n\nfor annotation in fig['layout']['annotations']:\n    annotation['font'] = {'size': 12, 'color': 'black'}\n\n# Show the figure\nfig.show()\n\n\n\n                                                \n\n\n\nUseful Variables\nBy trying each numerical variable as a color metric for the scatter plots, four important features that I found are as below:\n\nVWC_Summer_whole\nWetSoilDays_Spring_whole\nSWA_Fall_whole\nBare\n\nFor now, rather than focusing on the seasonality of the variables, lets focus on VWC, WetSoilDays, SWA and Bare. We can infer that it is important to keep the land moist to a certain level and minimize the ‘bareness’ in the area to lower the temperature. Lets move on to each RCP scenario for a more detailed analysis.\n\n\nImportant Features\nfeature = 'VWC_Summer_whole'\nfig = px.scatter(df_con[df_con['year'].isin(range(2060,2099))], x=\"PPT_Annual\", y=\"T_Annual\",\n                 color=feature, facet_col=\"RCP\",     \n                 labels={\n        feature: 'Scale'  # Replace with your desired colorbar title\n    })\nfig.update_layout(\n    title={\n        'text': f'&lt;b&gt;Annual Precipitation/Temperature ({feature})&lt;/b&gt;',\n        # 'y':0.95,  # This adjusts the position of the title (vertically)\n        'x':0.5,   # Centers the title horizontally\n        'xanchor': 'center',  # Ensures the title is centered at the specified x position\n        # 'yanchor': 'top'  # Ensures the title is positioned based on the top of the text\n    },\n    title_font=dict(size=20)  # Custom font settings\n)\nfig.show()\n\n\nfeature = 'WetSoilDays_Spring_whole'\nfig = px.scatter(df_con[df_con['year'].isin(range(2060,2099))], x=\"PPT_Annual\", y=\"T_Annual\",\n                 color=feature, facet_col=\"RCP\",     \n                 labels={\n        feature: 'Scale'  # Replace with your desired colorbar title\n    })\nfig.update_layout(\n    title={\n        'text': f'&lt;b&gt;Annual Precipitation/Temperature ({feature})&lt;/b&gt;',\n        # 'y':0.95,  # This adjusts the position of the title (vertically)\n        'x':0.5,   # Centers the title horizontally\n        'xanchor': 'center',  # Ensures the title is centered at the specified x position\n        # 'yanchor': 'top'  # Ensures the title is positioned based on the top of the text\n    },\n    title_font=dict(size=20)  # Custom font settings\n)\n\nfig.show()\n\nfeature = 'SWA_Fall_whole'\nfig = px.scatter(df_con[df_con['year'].isin(range(2060,2099))], x=\"PPT_Annual\", y=\"T_Annual\",\n                 color=feature, facet_col=\"RCP\",     \n                 labels={\n        feature: 'Scale'  # Replace with your desired colorbar title\n    })\nfig.update_layout(\n    title={\n        'text': f'&lt;b&gt;Annual Precipitation/Temperature ({feature})&lt;/b&gt;',\n        # 'y':0.95,  # This adjusts the position of the title (vertically)\n        'x':0.5,   # Centers the title horizontally\n        'xanchor': 'center',  # Ensures the title is centered at the specified x position\n        # 'yanchor': 'top'  # Ensures the title is positioned based on the top of the text\n    },\n    title_font=dict(size=20)  # Custom font settings\n)\n\nfig.show()"
  },
  {
    "objectID": "Overview_Analysis.html#pearson-correlation",
    "href": "Overview_Analysis.html#pearson-correlation",
    "title": "Dataset Analysis",
    "section": "Pearson Correlation",
    "text": "Pearson Correlation\nWhat is Pearson Correlation? Pearson correlation is a measure of the linear relationship between two continuous variables. It quantifies the degree to which a change in one variable predicts a change in another variable, with values ranging from -1 to +1. A value of +1 indicates a perfect positive linear relationship, where an increase in one variable corresponds to a proportional increase in the other. A value of -1 indicates a perfect negative linear relationship, where an increase in one variable corresponds to a proportional decrease in the other. A value of 0 indicates that there is no linear relationship between the variables.\n\nRCP4.5\nBy calculating a Pearson correlation matrix for all numerical variables in the dataset, we can create a heatmap to explore the relationships between different features. This visualization helps identify which features affect each other and highlights those that correlate most strongly with the annual temperature.\nIn the second plot below which is a plot for features sorted for most correlated with T_Annual, we see that the highest correlators are:\n\nExtreme Short Term dry stress\nFrost days\n\nWhile these factors cannot be directly influenced, some takeaways from the plot would be that we can take action on the following factors which were the next highly ranked groups to mitigate temperature rise:\n\nPET (Potential Evapotranspiration)\nSWA (Soil Water Availability)\nVWC (Volumetric Water Content)\n\n\n\nCorrelation Heatmap\n# Calculate the correlation matrix\ncorr_matrix = df_orig[(df_orig['TimePeriod']!='Hist') & (df_orig['RCP']==4.5)].iloc[:,8:].corr()\n\n\n# Create an interactive heatmap of the correlation matrix\nfig = px.imshow(corr_matrix,\n                # text_auto=True,  # Automatically add text in each cell\n                labels=dict(color=\"Correlation\"),\n                x=corr_matrix.columns,\n                y=corr_matrix.columns,\n                color_continuous_scale='RdBu_r'\n  )  # Red-Blue color map, reversed\n\nfig.update_layout(\n    width=800,  # Width of the figure in pixels\n    height=900,  # Height of the figure in pixels\n    margin=dict(l=10, r=1, t=50, b=10)  # Reducing margins around the plot\n)\n\n# Adjusting color bar position\n# fig.update_layout(coloraxis_colorbar=dict(\n#     x=0.8  # Adjusts the horizontal position of the color bar\n# ))\nfig.update_layout(title_text='&lt;b&gt;Future Correlation Heatmap : RCP 4.5&lt;/b&gt;',  # Bold text using HTML\n                  title_x=0.5)  # Centers the title by setting the x position to 0.5\n\nfig.update_xaxes(tickfont=dict(size=10))  # Sets the font size of x-axis labels\nfig.update_yaxes(tickfont=dict(size=10))  # Sets the font size of y-axis labels\n# fig.update_xaxes(side=\"bottom\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCorrelation Feature Importance\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = corr_matrix['T_Annual'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(20).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(corr_matrix['T_Annual'].loc[top_features,],4)[1:]\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to Annual Temperature (RCP = 4.5)&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nRCP8.5\nIn the analysis of Pearson correlation for different RCP (Representative Concentration Pathway) scenarios, it was observed that the ranking of features changed between the RCP 4.5 and RCP 8.5 scenarios. Here’s a detailed comparison:\n\nSimilarities:\n\nHigher ranked features are extreme short term dry stress and Frost Days\nLower ranked features are VWC, SWA and PET\n\n\n\nDifferences:\n\nCorrelation gap between higher ranked and lower Ranked Features\n\nRCP 4.5 : The transition from higher to lower ranked features seem smooth on the plot and highest ranked VWC feature has a correlation of -0.37.\nRCP 8.5 : There is an abrupt change when shifting to lower ranked features and the first VWC feature has a correlation of -0.26 which is significantly lower than the RCP 4.5 scenario.\n\nRCP 8.5 Scenario:\n\nTemperature-Related Variables: There was a noticeable increase in the number of temperature-related variables such as Tmin (minimum temperature) and Tmax (maximum temperature).\nDecrease in VWC and SWA Features: The number of VWC and SWA features significantly decreased, and their places in the ranking were taken over by temperature-related variables.\n\n\n\n\nImplications:\n\nRCP 4.5: This scenario suggests room for human actions to influence annual temperature.\nRCP 8.5: Under this more extreme scenario, unchangable variables become more dominant, overshadowing the influence of water-related variables, therefore implying that it is harder to influence temperature.\n\nThese differences highlight how the impact of climate variables can shift under different greenhouse gas concentration pathways, with temperature effects becoming more pronounced under higher emission scenarios.\nWhat does this mean? With the knowledge that 8.5 means higher CO2 emission as mentioned in the EDA tab, we can imply that if the RCP8.5 scenario takes place, there is less room for people to prevent temperatures from rising and preserving the environment. This is a logical statement even without the data but the data reinforces the idea by showing less variables in the pearson correlation with the annual temperature.\n\n\nCorrelation Heatmap\n# Calculate the correlation matrix\ncorr_matrix = df_orig[(df_orig['TimePeriod']!='Hist') & (df_orig['RCP']==8.5)].iloc[:,8:].corr()\n\n\n# Create an interactive heatmap of the correlation matrix\nfig = px.imshow(corr_matrix,\n                # text_auto=True,  # Automatically add text in each cell\n                labels=dict(color=\"Correlation\"),\n                x=corr_matrix.columns,\n                y=corr_matrix.columns,\n                color_continuous_scale='RdBu_r'\n  )  # Red-Blue color map, reversed\n\nfig.update_layout(\n    width=800,  # Width of the figure in pixels\n    height=900,  # Height of the figure in pixels\n    margin=dict(l=10, r=1, t=50, b=10)  # Reducing margins around the plot\n)\n\n# Adjusting color bar position\n# fig.update_layout(coloraxis_colorbar=dict(\n#     x=0.8  # Adjusts the horizontal position of the color bar\n# ))\nfig.update_layout(title_text='&lt;b&gt;Future Correlation Heatmap : RCP 8.5&lt;/b&gt;',  # Bold text using HTML\n                  title_x=0.5)  # Centers the title by setting the x position to 0.5\n\nfig.update_xaxes(tickfont=dict(size=10))  # Sets the font size of x-axis labels\nfig.update_yaxes(tickfont=dict(size=10))  # Sets the font size of y-axis labels\n# fig.update_xaxes(side=\"bottom\")\nfig.show()\n\n\n\n                                                \n\n\n\n\nCorrelation Feature Importance\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = corr_matrix['T_Annual'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(20).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(corr_matrix['T_Annual'].loc[top_features,],4)[1:]\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to Annual Temperature&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()"
  },
  {
    "objectID": "Overview_Analysis.html#rmse",
    "href": "Overview_Analysis.html#rmse",
    "title": "Dataset Analysis",
    "section": "RMSE",
    "text": "RMSE\nTo identify the most significant differences between two scenarios, I employed another method: calculating the RMSE (Root Mean Square Error) for each column. Given that both scenarios have the same number of data points, this approach provided an effective way to quantify the differences. Before performing the RMSE calculations, I standardized the data points to ensure consistency.\nWhen analyzing differences using RMSE, precipitation-related features stood out as the most variable between the two scenarios. Interestingly, it wasn’t always the scenario with the highest precipitation that had the lower temperature. The most surprising difference was in PPT_Fall, identified as the most significant discrepancy. Scenario 37 had higher fall precipitation than Scenario 40. However, Scenario 40 exhibited higher annual precipitation, greater summer precipitation, and even more evaporation during the summer.\nWhat does this mean? Seasonality of features could affect the annual temperature more than the annual featuers itself. Although the current analysis is on scenarios, a future research on analyzing seasons could be a plausible approach to predict annual temperature.\n\n\nRMSE\ndf_45 = df_orig[df_orig['RCP'] == 4.5]\ndf_85 = df_orig[df_orig['RCP'] == 8.5]\n\ndf1 = df_45.iloc[:,8:-3]\ndf2 = df_85.iloc[:,8:-3]\n\n# Function to calculate z-scores\ndef standardize(df):\n    return df.apply(zscore)\n\n# Standardize both dataframes\nz_df1 = standardize(df1)\nz_df2 = standardize(df2)\n\n# Calculate Absolute Difference of Z-Scores\nabs_diff_z_scores = np.abs(z_df1 - z_df2)\n\n# Mean Absolute Difference\nmean_abs_diff = abs_diff_z_scores.mean()\n\n# RMSE\nrmse = np.sqrt(np.mean((z_df1.reset_index(drop=True) - z_df2.reset_index(drop=True))**2, axis=0))\n\nrmse_sort = rmse.sort_values(ascending=False).head(20)\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=rmse_sort.keys(),\n    y=rmse_sort.values,\n    text=[round(i,4) for i in rmse_sort.values],  # Show the actual values as text\n    textposition='inside',\n    # marker_color=colors,\n    showlegend=False\n)])\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;RCP 4.5 vs 8.5 RMSE of components&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\nfor i, feature in enumerate(rmse_sort.keys()[:5]):\n    print(\"Rank : \", i+1)\n    print(f\"RCP 4.5 Average {feature} : \", df_45[feature].mean())\n    print(f\"RCP 8.5 Average {feature} : \", df_85[feature].mean())\n    print(\"\")\n\n\n\n                                                \n\n\nRank :  1\nRCP 4.5 Average FrostDays_Summer :  0.00022957468556467173\nRCP 8.5 Average FrostDays_Summer :  0.00011478734278233587\n\nRank :  2\nRCP 4.5 Average PPT_Fall :  9.65464850475821\nRCP 8.5 Average PPT_Fall :  9.665259282743092\n\nRank :  3\nRCP 4.5 Average PPT_Spring :  6.52676644055382\nRCP 8.5 Average PPT_Spring :  6.369110562075354\n\nRank :  4\nRCP 4.5 Average Evap_Spring :  4.403702479181158\nRCP 8.5 Average Evap_Spring :  4.269294863702628\n\nRank :  5\nRCP 4.5 Average PPT_Summer :  8.145404406740747\nRCP 8.5 Average PPT_Summer :  8.249074486053336"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Dataset EDA",
    "section": "",
    "text": "Import module / Set options and theme\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy.stats import ttest_rel\nfrom statsmodels.stats.weightstats import ttest_ind\nimport numpy as np\nimport pingouin as pg\nfrom scipy.stats import zscore\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)\nImport cleaned data\ndf = pd.read_csv('../data/cleaned_df.csv')\ndf['Location_ID'] = df.groupby(['long', 'lat']).ngroup() + 1"
  },
  {
    "objectID": "EDA.html#average-scenarios",
    "href": "EDA.html#average-scenarios",
    "title": "Dataset EDA",
    "section": "Average Scenarios",
    "text": "Average Scenarios\nThe Average Scenarios dataset averages all the numerical columns of the scenarios into one row, outputing one row for each Location, Year, and RCP. This dataset is used when conducting EDA and visualizing overtrend\n\n\nClean data (Average Scenarios)\ngroup_list = ['Park', 'long', 'lat', 'veg', 'year', 'TimePeriod', 'RCP','treecanopy', 'Ann_Herb', 'Bare', 'Herb', 'Litter', 'Shrub', 'El', 'Sa','Cl', 'RF', 'Slope', 'E', 'S']\nveg_location = df.drop(labels='scenario',axis=1).groupby(group_list).mean().reset_index()\n# veg_location['T_Annual'] = (veg_location['T_Annual'] - veg_location['T_Annual'].min()) / (veg_location['T_Annual'].max() - veg_location['T_Annual'].min())\n\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(veg_location['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\nveg_location['RCP'] = numeric_series.fillna(veg_location['RCP'])\n\nfour = veg_location[veg_location['RCP'].isin([4.5])]\neight = veg_location[veg_location['RCP'].isin([8.5])]\nfour_h = veg_location[veg_location['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = veg_location[veg_location['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_con = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_con['Location_ID'] = df_con.groupby(['long', 'lat']).ngroup() + 1\n\ndf_con.head(5)\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\nRL\nLocation_ID\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\n13.79\n8.71\n2.69\n6.37\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\n-12.45\n-7.35\n5.55\n-10.25\n0.2370806\n5.296833\n1.067496\n1.9667860\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\n31.56\n11.21352505\n54.57202074\n1\n\n\n1\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\n2.25\n9.81\n9.39\n11.75\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\n-9.35\n-5.55\n1.25\n-7.25\n0.2930753\n3.506108\n3.916328\n2.7875470\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\n33.20\n12.18369600\n54.57202074\n1\n\n\n2\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\n4.12\n5.10\n9.50\n9.83\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\n-16.55\n-7.25\n5.65\n-6.25\n0.2453347\n3.105047\n3.523923\n2.8900990\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\n28.55\n10.34575711\n54.57202074\n1\n\n\n3\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\n7.09\n10.80\n10.22\n10.40\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\n-15.05\n-7.25\n3.85\n-8.95\n0.2252735\n4.962824\n5.006576\n1.1952350\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\n38.51\n10.27104410\n54.57202074\n1\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\n4.5\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\n4.77\n4.32\n9.49\n8.17\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\n-18.45\n-8.45\n2.95\n-12.45\n0.1226868\n3.120243\n4.269040\n0.9273169\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\n26.75\n10.20010025\n54.57202074\n1"
  },
  {
    "objectID": "EDA.html#all-scenarios",
    "href": "EDA.html#all-scenarios",
    "title": "Dataset EDA",
    "section": "All Scenarios",
    "text": "All Scenarios\n\n\nCode\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(df['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\ndf['RCP'] = numeric_series.fillna(df['RCP'])\n\nfour = df[df['RCP'].isin([4.5])]\neight = df[df['RCP'].isin([8.5])]\nfour_h = df[df['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = df[df['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_orig = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_orig['Location_ID'] = df_orig.groupby(['long', 'lat']).ngroup() + 1\n\ndf_orig.head(5)\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\nRL\nLocation_ID\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\n13.79\n8.71\n2.69\n6.37\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\n-12.45\n-7.35\n5.55\n-10.25\n0.2370806\n5.296833\n1.067496\n1.9667860\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\n31.56\n11.21352505\n54.57202074\n1\n\n\n1\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\n2.25\n9.81\n9.39\n11.75\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\n-9.35\n-5.55\n1.25\n-7.25\n0.2930753\n3.506108\n3.916328\n2.7875470\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\n33.20\n12.18369600\n54.57202074\n1\n\n\n2\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\n4.12\n5.10\n9.50\n9.83\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\n-16.55\n-7.25\n5.65\n-6.25\n0.2453347\n3.105047\n3.523923\n2.8900990\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\n28.55\n10.34575711\n54.57202074\n1\n\n\n3\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\n7.09\n10.80\n10.22\n10.40\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\n-15.05\n-7.25\n3.85\n-8.95\n0.2252735\n4.962824\n5.006576\n1.1952350\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\n38.51\n10.27104410\n54.57202074\n1\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\n4.5\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\n4.77\n4.32\n9.49\n8.17\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\n-18.45\n-8.45\n2.95\n-12.45\n0.1226868\n3.120243\n4.269040\n0.9273169\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\n26.75\n10.20010025\n54.57202074\n1"
  },
  {
    "objectID": "EDA.html#basic-statistics",
    "href": "EDA.html#basic-statistics",
    "title": "Dataset EDA",
    "section": "Basic Statistics",
    "text": "Basic Statistics\nBasic Statistics\n\n79 years of prediction (2021~2099)\n40 scenarios (sc22~sc61)\n2 RCP scenarios(4.5, 8.5)\n113 locations\n\nExplanation\n\nThe data is collected over 113 locations within the Natural Bridge National Monument. (Number of Unique latitude, longitude combinations)\nThis dataset is composed of 41 years of historical data and 79 years worth of predictions. Since there can be only one scenario for past data, all historical data is labeled as ‘sc1’ or scenario one\nFrom the predicted years (2021 to 2099), There are two RCP scenarios which changes only the RCP variable and 40 scenarios which simulate 86 other variables.\n\nBased on each combination of scenarios, a prediction is made for each location point regarding various columns of the dataset including annual and seasonal percipitation, seasonal dry soil days, seasonal evaporation, seasonal extreme short term dry stress, soil water availability to output a final prediction for Annual and seasonal temperatures.\nWhat is RCP?\nRepresentative Concentration Pathways : A group of scenarios where CO2 emmission is predicted like the image below\n\nThe dataset consists of two RCP scenarios 4.5 and 8.5\n\n\nsource : Representative Concentration Pathway. (2024, May 2). In Wikipedia. https://en.wikipedia.org/wiki/Representative_Concentration_Pathway"
  },
  {
    "objectID": "EDA.html#location",
    "href": "EDA.html#location",
    "title": "Dataset EDA",
    "section": "Location",
    "text": "Location\nWhere is this data located and how does it look like?\nThe data points were sampled at the Natural Bridge National Monument in Utah. And for a better idea of The plots below show two different location aspects of the dataset. The first plot is the average annual temperature for each location point in the year 2099. Since the temperature for predictions increase over time, the last year for the dataset was chosen for a more dramatic comparison\nThe second plot is a scatter plot of the locations of vegetations. By comparing the two graphs, we can tell that there isn’t much correlation with vegetation and annual temperature but rather a correlation with the location(latitude, longitude) and temperature. We will get to this in the following visualizations.\n\n\nMap Visualizations\nmap = df_con[df_con['year']==2099].groupby(['long','lat'])['T_Annual'].mean().reset_index()\n\nfiltered_df = map\nfig = px.scatter_mapbox(filtered_df, lat=\"lat\", lon=\"long\", color=\"T_Annual\", size=\"T_Annual\",\n                  color_continuous_scale=px.colors.cyclical.IceFire, size_max=8, zoom=11,\n                  mapbox_style=\"open-street-map\")\n\nfig.update_layout(\n    title={\n        'text': \"&lt;b&gt;Average Temperature (2099) &lt;/b&gt;\",\n        'y': 0.97,\n        'x': 0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    margin={\"r\": 0, \"t\": 40, \"l\": 0, \"b\": 0}\n    )\n\nfig.show()\n\nmap = df_con[df_con['year']==2099].groupby(['long','lat','veg']).size().reset_index()\n\nfiltered_df = map\n\n# Create the scatter mapbox\nfig = px.scatter_mapbox(map, lat=\"lat\", lon=\"long\", color=\"veg\",\n                        color_continuous_scale=px.colors.cyclical.IceFire, size_max=8, zoom=11,\n                        mapbox_style=\"open-street-map\")\n\n# Update the layout with the new legend title and position\nfig.update_layout(\n    title={\n        'text': \"&lt;b&gt;Vegetation Location&lt;/b&gt;\",\n        'y': 0.97,\n        'x': 0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'\n    },\n    coloraxis_colorbar={\n        'title': 'Vegetation Level'  # Change this to your desired legend title\n    },\n    legend={\n        'x': 1,  # Position the legend to the right\n        'y': 0.8,  # Center the legend vertically\n        'xanchor': 'left',  # Anchor the legend's x position to the left side\n        'yanchor': 'middle'  # Anchor the legend's y position to the middle\n    },\n    margin={\"r\": 0, \"t\": 40, \"l\": 0, \"b\": 0}\n)\nfig.update_traces(marker=dict(size=10))  # Set the desired fixed marker size\n\n# Show the figure\nfig.show()"
  },
  {
    "objectID": "EDA.html#temperaturepercipitation-trends",
    "href": "EDA.html#temperaturepercipitation-trends",
    "title": "Dataset EDA",
    "section": "Temperature/Percipitation Trends",
    "text": "Temperature/Percipitation Trends\nThe following plots were drawn by averaging all scenarios, locations, and RCPs for a given year for annual temperature and annual percipitation to see the overall trend of the predictions of the dataset. Predictions were made from the year 2021 which is\nWe can see that the predictions portray an increase in temperature but a fluctuation with percipitation allowing us to make an educated guess that temperature is the more important variable for RCP scenarios which deal with CO2 emission.\n\n\nTemperature / Percipitation Predictions Overview\n# Assuming 'veg_location' is your DataFrame\n# Filter the DataFrame for 'RCP' values 'historical' and 4.5\nfiltered_data = df_con.groupby(['year'])['T_Annual'].mean().reset_index()\n\n# Create the line plot\nfig = px.line(\n    data_frame=filtered_data,\n    x='year',\n    y='T_Annual',\n    title='&lt;b&gt;Annual Temperature&lt;/b&gt;',\n    labels={'T_Annual': 'Annual Temperature'},\n    line_shape='spline'\n)\n\n# Add a vertical line at year 2021\nfig.add_shape(\n    dict(\n        type='line',\n        x0=2021,\n        y0=filtered_data['T_Annual'].min()/1.1,\n        x1=2021,\n        y1=filtered_data['T_Annual'].max()*1.1,\n        line=dict(\n            color=\"Red\",\n            width=2,\n            dash=\"dash\",\n        ),\n    )\n)\n\nfig.add_annotation(\n    dict(\n        x=2021,  # Position the text to the right of the line\n        y=filtered_data['T_Annual'].max(),  # Position the text at the middle of the y-axis\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Prediction\",\n        showarrow=False,\n        font=dict(\n            size=12,\n            color=\"Red\"\n        ),\n        align=\"center\",\n        xanchor=\"left\"\n    )\n)\n\nfig.update_layout(title={'x':0.5})\n# Show the plot\nfig.show()\n\n\n# Assuming 'veg_location' is your DataFrame\n# Filter the DataFrame for 'RCP' values 'historical' and 4.5\nfiltered_data = df_con.groupby(['year'])['PPT_Annual'].mean().reset_index()\n\n# Create the line plot\nfig = px.line(\n    data_frame=filtered_data,\n    x='year',\n    y='PPT_Annual',\n    title='&lt;b&gt;Annual Precipitation&lt;/b&gt;',\n    labels={'T_Annual': 'Annual Temperature'},\n    line_shape='spline'\n)\n\n# Add a vertical line at year 2021\nfig.add_shape(\n    dict(\n        type='line',\n        x0=2021,\n        y0=filtered_data['PPT_Annual'].min()/1.1,\n        x1=2021,\n        y1=filtered_data['PPT_Annual'].max()*1.1,\n        line=dict(\n            color=\"Red\",\n            width=2,\n            dash=\"dash\",\n        ),\n    )\n)\n\nfig.add_annotation(\n    dict(\n        x=2021,  # Position the text to the right of the line\n        y=filtered_data['PPT_Annual'].max(),  # Position the text at the middle of the y-axis\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Prediction\",\n        showarrow=False,\n        font=dict(\n            size=12,\n            color=\"Red\"\n        ),\n        align=\"center\",\n        xanchor=\"left\"\n    )\n)\n\nfig.update_layout(title={'x':0.5})\n# Show the plot\nfig.show()"
  },
  {
    "objectID": "cleaning.html",
    "href": "cleaning.html",
    "title": "Dataset Cleaning",
    "section": "",
    "text": "Import Module\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)"
  },
  {
    "objectID": "cleaning.html#clean-data-provided",
    "href": "cleaning.html#clean-data-provided",
    "title": "Dataset Cleaning",
    "section": "Clean Data (Provided)",
    "text": "Clean Data (Provided)\nThe clean data seems to have filtered out many columns and rows. In order to figure out what was filtered, I impolemented a few filters on the original dataset to see if I could get the same shape as the clean data.\n\nFilter columns\nFilter years 2021~2024\n\n\n\nImport Clean Data\nclean_df = pd.read_csv('../data/nearterm_data_2020-2024.csv')\n\nprint(\"How does the clean dataset look like?\")\nclean_df.head()\n\n\nHow does the clean dataset look like?\n\n\n\n\n\n\n\n\n\nlong\nlat\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nDrySoilDays_Summer_whole\nEvap_Summer\nExtremeShortTermDryStress_Summer_whole\nFrostDays_Winter\nNonDrySWA_Summer_whole\nPPT_Winter\nPPT_Summer\nPPT_Annual\nT_Winter\nT_Summer\nT_Annual\nTmax_Summer\nTmin_Winter\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\n\n\n\n\n0\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc22\n0\n0\n84\n5\n11\n7\nNaN\nNaN\nNaN\nNaN\nNaN\n5.94\n6.37\n6.37\n1.6303330\n24.50402\n24.50402\n36.89\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc22\n0\n0\n84\n5\n11\n7\n0.0\n3.2422296149\n36.314\n73.0\n0.0929865127\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-12.77\n0.1146518092\n0.0787639891\n0.0435142642\n0.0512810069\n\n\n2\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc23\n0\n0\n84\n5\n11\n7\nNaN\nNaN\nNaN\nNaN\nNaN\n6.44\n3.09\n3.09\n1.3890560\n24.11043\n24.11043\n37.95\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc23\n0\n0\n84\n5\n11\n7\n0.0\n2.4016114656\n36.510\n71.0\n0.0001057892\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-18.96\n0.1302210687\n0.0964121637\n0.0412322081\n0.0922413330\n\n\n4\n-110.0472\n37.60413\n2021\nNT\n4.5\nsc24\n0\n0\n84\n5\n11\n7\nNaN\nNaN\nNaN\nNaN\nNaN\n5.35\n5.32\n6.87\n-0.3343889\n25.54266\n10.31321\n37.74\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nImport Raw Data and Filter\ndf = pd.read_csv('../data/NABR_ClimExposure', delimiter=' ')\nclean_m = df[(df['year'] &gt;= 2021) & (df['year'] &lt;= 2024)]\nclean_m = clean_m.loc[:, clean_m.columns.isin(list(clean_df.columns))]\n\nprint(\"Given Clean Dataset shape : \", clean_df.shape)\nprint(\"Filtered Original Dataset shape : \", clean_m.shape)\n\n\nGiven Clean Dataset shape :  (55802, 29)\nFiltered Original Dataset shape :  (55802, 29)"
  },
  {
    "objectID": "cleaning.html#conclusion",
    "href": "cleaning.html#conclusion",
    "title": "Dataset Cleaning",
    "section": "Conclusion",
    "text": "Conclusion\nSince the clean data was adding two filters to the original dataset, I decided to clean the original dataset to extract as much information as possible."
  },
  {
    "objectID": "cleaning.html#finding-patterns",
    "href": "cleaning.html#finding-patterns",
    "title": "Dataset Cleaning",
    "section": "Finding Patterns",
    "text": "Finding Patterns\nFirst we will try to find a pattern in how to clean the dataset. What is the unique identity for each row?\nBy grouping vegetation, longitude, latitude, year, and scenario, we know that this isn’t enough to get a unique row. Lets subset one combination to see what rows are in the given combination.\n\n\nGroup Datasets\nnumber_test = df.groupby(['veg','long','lat','year','scenario']).size().reset_index()\nnumber_test.rename({0:'Size'},axis=1,inplace=True)\nnumber_test[number_test['Size'] &gt; 2].head()\n\n\n\n\n\n\n\n\n\nveg\nlong\nlat\nyear\nscenario\nSize\n\n\n\n\n1\nForest\n-110.0348\n37.59067\n1981\nsc1\n5\n\n\n3\nForest\n-110.0348\n37.59067\n1983\nsc1\n5\n\n\n5\nForest\n-110.0348\n37.59067\n1985\nsc1\n5\n\n\n7\nForest\n-110.0348\n37.59067\n1987\nsc1\n5\n\n\n9\nForest\n-110.0348\n37.59067\n1989\nsc1\n5"
  },
  {
    "objectID": "cleaning.html#subset-examination",
    "href": "cleaning.html#subset-examination",
    "title": "Dataset Cleaning",
    "section": "Subset Examination",
    "text": "Subset Examination\nBy looking at the subset of a dataset below, we can see a few interesting points about this dataset\n\nIssue 1\nIt seems like there are many duplicates but no rows are erased when erasing duplicates Why?\n\nFor the first four rows, all the data seem to be duplicates. What’s different?\n\nThe T_Annual and PPT_Annual seem to be different when all other features are the same.\nT_Annual and PPT_Annual seem to be one of the season measurements.\nA standard of unique rows must be defined for meaningful analysis.\n\n\n\n\nSolution 1\n\nRemove T_Annual PPT_Annual columns\nRemove duplicates\nFind the sum of seasonal percipitation and re-define PPT_Annual\nFind the average of seasonal temperatures and re-define T_Annual\n\n\n\nData Subset of one specific identifier\ndf[(df['veg'] == 'Forest') & (df['year'] == 1981) & (df['long'] == -110.0348) & (df['lat'] == 37.59067) & (df['scenario'] == 'sc1')]\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nRL\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nPPT_Annual\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nT_Annual\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\n\n\n\n\n106077\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n9.69\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n3.393333\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106078\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n9.69\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n23.108700\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106079\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n2.37\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n3.393333\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106080\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.37\n10.16\n9.69\n12.45\n2.37\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.393333\n10.47446\n23.1087\n11.46374\n23.108700\n16.95\n28.05\n37.45\n29.55\nNaN\nNaN\nNaN\nNaN\n0.1318164\n5.268698\n4.032515\n2.26957\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n106081\nNABR\n-110.0348\n37.59067\nForest\n1981\nHist\nhistorical\nsc1\n0\n0\n47\n10\n19\n19\n1792.537\n72.9846\n8.094261\n2.230278\n65.21617\n634.6172\n-1960.326\n-9690.729\n0.3326521\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n1.308474\n6.044908\n5.147714\n4.197853\nNaN\n24.52\n35.96\nNaN\nNaN\n24.52\n35.96\nNaN\n74.0\n26.0\n0.0\n13.0\n1.667453\n2.089958\n0.03898182\n3.199576\n1.876374\n2.415431\n0.03898184\n3.740458\n3.187145\n29.85291\n47.89414\n15.6124\nNaN\nNaN\nNaN\nNaN\nNaN\n11.0\n11.0\n1.667453\n2.089958\n0.03898182\n3.199576\n1.876374\n2.415431\n0.03898184\n3.740458\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-9.35\n-5.55\n0.95\n-7.25\nNaN\nNaN\nNaN\nNaN\n0.0835052\n0.09223872\n0.04992899\n0.115007\n0.07972316\n0.08898326\n0.04818989\n0.1116202\n90.0\n73.0\n14.0\n89.0\n90.0\n73.0\n14.0\n89.0\n\n\n\n\n\n\n\n\n\nData Cleaning 1\n# Columns to exclude\ncols_to_exclude = ['PPT_Annual', 'T_Annual']\n\n# Create a boolean mask for columns to keep\nmask = df.columns.isin(cols_to_exclude)\n\n# Use loc to select all rows and only the columns not in the mask\nnew_df = df.loc[:, ~mask]\n\ntest = new_df.drop_duplicates()\n\nnumber = test.groupby(['veg','year','long','lat','scenario']).size().reset_index()\nnumber.rename({0:'Size'},axis=1,inplace=True)\n\n# number[number['Size'] &gt; 2]\n\ntest['PPT_Annual'] = test['PPT_Winter'] + test['PPT_Spring'] + test['PPT_Summer'] + test['PPT_Fall']\ntest['T_Annual'] = (test['T_Winter'] + test['T_Spring'] + test['T_Summer'] + test['T_Fall'])/4\n\n\n\n\nIssue 2\nMissing Column values as if extracted by two different sources at the same site\n\nAlthough the so called “identifiers” that I defined were the same, a the value of a group of columns were stored in row A and another group of columns were stored in row B.\n\nRow A and Row B have identical identifiers.\nWhen a column has a value in row A, row B has a null value in the same column\nThe RL column (Depth of Restriction Layer) is slightly different for the two identifiers (Same to fifth decimal point)\nSince the RL was similar, I was willing to sacrifice the fifth decimal point precision for ease of analysis.\n\n\n\n\nSolution 2\n\nRemove RL column but store if with the identifiers\nGroup by the identifiers and fine the average RL.\nWith the original dataset with RL removed, Merge the two rows together vertically so that the null values and data points for identical identifiers merge together.\njoin the average RL and original dataset with identifiers as the joinint key\n\n\n\nBefore cleaning\ntest.head(10)\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nRL\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n13.79\n8.71\n2.69\n6.37\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\nNaN\nNaN\nNaN\nNaN\n0.2370806\n5.296833\n1.067496\n1.9667860\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n31.56\n11.21352505\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\nNaN\nNaN\nNaN\nNaN\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-12.45\n-7.35\n5.55\n-10.25\nNaN\nNaN\nNaN\nNaN\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\nNaN\nNaN\n\n\n5\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.25\n9.81\n9.39\n11.75\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\nNaN\nNaN\nNaN\nNaN\n0.2930753\n3.506108\n3.916328\n2.7875470\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n33.20\n12.18369600\n\n\n6\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\nNaN\nNaN\nNaN\nNaN\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-9.35\n-5.55\n1.25\n-7.25\nNaN\nNaN\nNaN\nNaN\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\nNaN\nNaN\n\n\n7\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.12\n5.10\n9.50\n9.83\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\nNaN\nNaN\nNaN\nNaN\n0.2453347\n3.105047\n3.523923\n2.8900990\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n28.55\n10.34575711\n\n\n8\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\nNaN\nNaN\nNaN\nNaN\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-16.55\n-7.25\n5.65\n-6.25\nNaN\nNaN\nNaN\nNaN\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\nNaN\nNaN\n\n\n9\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n7.09\n10.80\n10.22\n10.40\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\nNaN\nNaN\nNaN\nNaN\n0.2252735\n4.962824\n5.006576\n1.1952350\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n38.51\n10.27104410\n\n\n10\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\nNaN\nNaN\nNaN\nNaN\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-15.05\n-7.25\n3.85\n-8.95\nNaN\nNaN\nNaN\nNaN\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\nNaN\nNaN\n\n\n11\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202000\n1949.283\n-8753.784\n4834.13\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n4.77\n4.32\n9.49\n8.17\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\nNaN\nNaN\nNaN\nNaN\n0.1226868\n3.120243\n4.269040\n0.9273169\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n26.75\n10.20010025\n\n\n15\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n54.57202148\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\nNaN\nNaN\nNaN\nNaN\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n-18.45\n-8.45\n2.95\n-12.45\nNaN\nNaN\nNaN\nNaN\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\nNaN\nNaN\n\n\n\n\n\n\n\n\n\nData Cleaning\na = test.drop('RL', axis=1)\nmerged_df = a.groupby(list(a.columns[0:21]), as_index=False).agg(lambda x: next(iter(x.dropna()), np.nan))\n\n\n\n\nData Cleaning\nrl = test.groupby(['veg','year','long','lat','scenario'])['RL'].mean().reset_index()\nmerged_df = pd.merge(merged_df, rl, on=['veg', 'year', 'long', 'lat', 'scenario'], how='inner')\n\n\n\n\nSanity Check\nprint(\"Original dataset rows with RL removed : \", merged_df.shape[0])\nprint(\"RL grouped and averaged by identifiers : \", rl.shape[0])\n\n\nOriginal dataset rows with RL removed :  361487\nRL grouped and averaged by identifiers :  361487\n\n\n\n\nCleaned Data\nmerged_df.head()\n\n\n\n\n\n\n\n\n\nPark\nlong\nlat\nveg\nyear\nTimePeriod\nRCP\nscenario\ntreecanopy\nAnn_Herb\nBare\nHerb\nLitter\nShrub\nEl\nSa\nCl\nRF\nSlope\nE\nS\nT_P_Corr\nDrySoilDays_Winter_top50\nDrySoilDays_Spring_top50\nDrySoilDays_Summer_top50\nDrySoilDays_Fall_top50\nDrySoilDays_Winter_whole\nDrySoilDays_Spring_whole\nDrySoilDays_Summer_whole\nDrySoilDays_Fall_whole\nEvap_Winter\nEvap_Spring\nEvap_Summer\nEvap_Fall\nExtremeShortTermDryStress_Winter_top50\nExtremeShortTermDryStress_Spring_top50\nExtremeShortTermDryStress_Summer_top50\nExtremeShortTermDryStress_Fall_top50\nExtremeShortTermDryStress_Winter_whole\nExtremeShortTermDryStress_Spring_whole\nExtremeShortTermDryStress_Summer_whole\nExtremeShortTermDryStress_Fall_whole\nFrostDays_Winter\nFrostDays_Spring\nFrostDays_Summer\nFrostDays_Fall\nNonDrySWA_Winter_top50\nNonDrySWA_Spring_top50\nNonDrySWA_Summer_top50\nNonDrySWA_Fall_top50\nNonDrySWA_Winter_whole\nNonDrySWA_Spring_whole\nNonDrySWA_Summer_whole\nNonDrySWA_Fall_whole\nPET_Winter\nPET_Spring\nPET_Summer\nPET_Fall\nPPT_Winter\nPPT_Spring\nPPT_Summer\nPPT_Fall\nSemiDryDuration_Annual_top50\nSemiDryDuration_Annual_whole\nSWA_Winter_top50\nSWA_Spring_top50\nSWA_Summer_top50\nSWA_Fall_top50\nSWA_Winter_whole\nSWA_Spring_whole\nSWA_Summer_whole\nSWA_Fall_whole\nT_Winter\nT_Spring\nT_Summer\nT_Fall\nTmax_Winter\nTmax_Spring\nTmax_Summer\nTmax_Fall\nTmin_Winter\nTmin_Spring\nTmin_Summer\nTmin_Fall\nTransp_Winter\nTransp_Spring\nTransp_Summer\nTransp_Fall\nVWC_Winter_top50\nVWC_Spring_top50\nVWC_Summer_top50\nVWC_Fall_top50\nVWC_Winter_whole\nVWC_Spring_whole\nVWC_Summer_whole\nVWC_Fall_whole\nWetSoilDays_Winter_top50\nWetSoilDays_Spring_top50\nWetSoilDays_Summer_top50\nWetSoilDays_Fall_top50\nWetSoilDays_Winter_whole\nWetSoilDays_Spring_whole\nWetSoilDays_Summer_whole\nWetSoilDays_Fall_whole\nPPT_Annual\nT_Annual\nRL\n\n\n\n\n0\nNABR\n-110.0472\n37.60413\nShrubland\n1980\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n-0.6636760860\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7140658366\n6.3995308949\n1.5598074021\n3.3632779979\nNaN\n24.34\n36.16\n29.52\nNaN\n24.34\n36.16\n29.52\n75.0\n34.0\n0.0\n26.0\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n7.7811633032\n31.1394527955\n48.0177480655\n21.9156825756\n13.79\n8.71\n2.69\n6.37\n36.5000000000\n36.5000000000\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n3.4668806371\n2.6546632530\n0.0321140671\n0.4880867481\n0.96483520\n8.767935\n23.15924\n11.962090\n14.15\n28.75\n37.05\n31.15\n-12.45\n-7.35\n5.55\n-10.25\n0.2370806\n5.296833\n1.067496\n1.9667860\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n0.1134468701\n0.0968307001\n0.0418759016\n0.0522975530\n91.0\n77.0\n5.0\n47.0\n91.0\n77.0\n5.0\n47.0\n31.56\n11.21352505\n54.57202074\n\n\n1\nNABR\n-110.0472\n37.60413\nShrubland\n1981\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3478010620\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n2.1815202084\n5.9723378265\n5.0428776741\n4.6374034668\n13.92\n26.53\n36.08\nNaN\n13.92\n26.53\n36.08\nNaN\n79.0\n26.0\n0.0\n13.0\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n8.1229049607\n32.3882557036\n48.1772426406\n21.7575735702\n2.25\n9.81\n9.39\n11.75\n13.2500000000\n13.2500000000\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n0.3461917264\n0.8982752558\n0.0336629893\n2.5013360811\n3.33444400\n10.548370\n23.27065\n11.581320\n17.05\n28.15\n37.55\n29.75\n-9.35\n-5.55\n1.25\n-7.25\n0.2930753\n3.506108\n3.916328\n2.7875470\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n0.0493818430\n0.0607271763\n0.0426386771\n0.0936706801\n48.0\n60.0\n13.0\n85.0\n48.0\n60.0\n13.0\n85.0\n33.20\n12.18369600\n54.57202074\n\n\n2\nNABR\n-110.0472\n37.60413\nShrubland\n1982\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.3260300992\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.2589947135\n4.7173273934\n4.5276363327\n4.2477717540\nNaN\n26.19\n34.99\n22.06\nNaN\n26.19\n34.99\n22.06\n83.0\n21.0\n0.0\n30.0\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n7.3379526955\n31.4894498184\n47.1800768757\n21.0684231651\n4.12\n5.10\n9.50\n9.83\n17.2857142857\n17.2857142857\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n3.2599844936\n1.5994982052\n0.1993822366\n1.2432253150\n-0.01555556\n9.472283\n22.05707\n9.869231\n14.35\n28.45\n36.65\n31.85\n-16.55\n-7.25\n5.65\n-6.25\n0.2453347\n3.105047\n3.523923\n2.8900990\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n0.1092341982\n0.0748166564\n0.0456102615\n0.0677891794\n90.0\n62.0\n19.0\n73.0\n90.0\n62.0\n19.0\n73.0\n28.55\n10.34575711\n54.57202074\n\n\n3\nNABR\n-110.0472\n37.60413\nShrubland\n1983\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.0388273872\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.7419915365\n6.2671578978\n5.1695757094\n3.7751048188\nNaN\n28.56\n33.69\n31.02\nNaN\n28.56\n33.69\n31.02\n85.0\n32.0\n0.0\n19.0\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n7.4798456947\n30.3128312703\n46.5762368398\n21.8471460016\n7.09\n10.80\n10.22\n10.40\n16.7142857143\n16.7142857143\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n3.8064480379\n2.9456592119\n0.0960442305\n1.5835966242\n0.40944440\n8.020652\n21.32826\n11.325820\n13.35\n30.65\n34.55\n33.15\n-15.05\n-7.25\n3.85\n-8.95\n0.2252735\n4.962824\n5.006576\n1.1952350\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n0.1204177901\n0.1025422325\n0.0441405046\n0.0748017843\n90.0\n74.0\n15.0\n69.0\n90.0\n74.0\n15.0\n69.0\n38.51\n10.27104410\n54.57202074\n\n\n4\nNABR\n-110.0472\n37.60413\nShrubland\n1984\nHist\nhistorical\nsc1\n0\n0\n84\n5\n11\n7\n1764.955\n77.03307\n6.082058\n2.285707\n1949.283\n-8753.784\n4834.13\n0.2166602692\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.6272686835\n5.0078604793\n5.2303324404\n4.0803373430\nNaN\n30.95\n34.01\n29.52\nNaN\n30.95\n34.01\n29.52\n91.0\n35.0\n0.0\n30.0\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n7.1730101555\n31.9972417196\n47.0386757592\n21.0183982059\n4.77\n4.32\n9.49\n8.17\n16.5000000000\n16.5000000000\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n3.7945975224\n1.7555326024\n0.0452782946\n1.3792575946\n-1.04725300\n9.853804\n21.95978\n10.034070\n10.25\n32.75\n35.35\n31.35\n-18.45\n-8.45\n2.95\n-12.45\n0.1226868\n3.120243\n4.269040\n0.9273169\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n0.1202091711\n0.0778415354\n0.0431793330\n0.0703661709\n91.0\n65.0\n16.0\n62.0\n91.0\n65.0\n16.0\n62.0\n26.75\n10.20010025\n54.57202074\n\n\n\n\n\n\n\n\n\nOutput to CSV\n# merged_df.to_csv('../data/cleaned_df.csv', index=False)"
  },
  {
    "objectID": "Analysis_45.html",
    "href": "Analysis_45.html",
    "title": "RCP 4.5 Analysis",
    "section": "",
    "text": "Now we’ll conduct a more detailed comparison within each RCP scenario(4.5, 8.5) to analyze how the highest temperature scenario and lowest temperature scenario within each group is similar or different.\nMethodology We will use t-SNE with pearson correlation and PCA to visualize these datapoints onto 2D and 3D planes to check if we can visually distinguish between the different scenarios. Then, we will use the original feature’s influence on the generated components to hypothesize what features effect the annual temperature the most.\n\n\nImport module / Set options and theme\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy.stats import ttest_rel\nfrom statsmodels.stats.weightstats import ttest_ind\nimport numpy as np\nimport pingouin as pg\nfrom scipy.stats import zscore\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)\n\n\n\n\nImport cleaned data\ndf = pd.read_csv('../data/cleaned_df.csv')\ndf['Location_ID'] = df.groupby(['long', 'lat']).ngroup() + 1\n\ngroup_list = ['Park', 'long', 'lat', 'veg', 'year', 'TimePeriod', 'RCP','treecanopy', 'Ann_Herb', 'Bare', 'Herb', 'Litter', 'Shrub', 'El', 'Sa','Cl', 'RF', 'Slope', 'E', 'S']\nveg_location = df.drop(labels='scenario',axis=1).groupby(group_list).mean().reset_index()\n# veg_location['T_Annual'] = (veg_location['T_Annual'] - veg_location['T_Annual'].min()) / (veg_location['T_Annual'].max() - veg_location['T_Annual'].min())\n\n\n# Average Scenario Dataset\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(veg_location['RCP'], errors='coerce')\n\n# Fill NaNs with original non-numeric values\nveg_location['RCP'] = numeric_series.fillna(veg_location['RCP'])\n\nfour = veg_location[veg_location['RCP'].isin([4.5])]\neight = veg_location[veg_location['RCP'].isin([8.5])]\nfour_h = veg_location[veg_location['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = veg_location[veg_location['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_con = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_con['Location_ID'] = df_con.groupby(['long', 'lat']).ngroup() + 1\n\n\n# Scenario Dataset\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(df['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\ndf['RCP'] = numeric_series.fillna(df['RCP'])\n\nfour = df[df['RCP'].isin([4.5])]\neight = df[df['RCP'].isin([8.5])]\nfour_h = df[df['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = df[df['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_orig = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_orig['Location_ID'] = df_orig.groupby(['long', 'lat']).ngroup() + 1\n\nselected_columns = [col for col in df.columns if not col.startswith(('T_', 'Tmin', 'Tmax'))]\ndropped_columns = [col for col in df.columns if col.startswith(('T_', 'Tmin', 'Tmax'))]\nfiltered_df = df_orig[selected_columns]\nfiltered_df['T_Annual'] = df_orig['T_Annual']\n\ndf_orig = filtered_df"
  },
  {
    "objectID": "Analysis_45.html#t-sne",
    "href": "Analysis_45.html#t-sne",
    "title": "RCP 4.5 Analysis",
    "section": "t-SNE",
    "text": "t-SNE\n\n2D/3D Plot\nSince we already conducted the same type of analysis on RCP = 8.5, lets just jump straight to the conclusions with the RCP 4.5 scenario and compare it with the 9.5 scenarios visualizations and results.\nThe similarity is that both the 2D plot and the 3D plot with all the scenarios are separated according to year and scenario like the RCP8.5 results. However, there seems to be little or no correlation between the t-SNE components and the scenarios with the lowest and highest temperature. Unlike the RCP8.5 plot which had patterns that we could group the two different scenarios, the RCP 4.5 results make it hard for us to group the two scenarios by visualizing them.\nMaybe we should take a different approach?\n\n\nt-SNE(RCP = 8.5)\ndata_1 = df_orig[(df_orig['RCP']==4.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\n\nselected_columns = [col for col in data_1.columns if 'summer' in col.lower()]\ndropped_columns = [col for col in data_1.columns if not 'summer' in col.lower()]\nfiltered_df = data_1[selected_columns]\n\n# Get the list of columns\ncolumns = filtered_df.columns\nratios = {}\n\n# Calculate the ratios\nfor i, col1 in enumerate(columns):\n    for col2 in columns[i+1:]:\n        ratio_col_name = f\"{col1}/{col2}\"\n        ratios[ratio_col_name] = filtered_df[col1] / filtered_df[col2]\n\nratios_df = pd.DataFrame(ratios)\n\neng_45 = pd.concat([data_1[dropped_columns], ratios_df], axis=1)\n\n\n# Step 1: Identify columns with inf or -inf\ncols_with_inf = eng_45.iloc[:,8:].columns.to_series()[np.isinf(eng_45.iloc[:,8:]).any()]\n\n# Step 2: Drop those columns\neng_45.drop(columns=cols_with_inf, inplace=True)\neng_45.dropna(inplace=True)\n\nX = eng_45.iloc[:,list(range(8, len(eng_45.columns)-1))]\ny = eng_45.iloc[:,len(eng_45.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=2, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\neng_45['tsne1'] = tsne_results[:, 0]\neng_45['tsne2'] = tsne_results[:, 1]\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    eng_45,\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For All Scenarios (RCP = 4.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    eng_45[eng_45['scenario'].isin(['sc37','sc40'])],\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For Scenario 60 and 58 (RCP = 4.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\n3D t-SNE (RCP = 4.5)\n# Step 1: Identify columns with inf or -inf\ncols_with_inf = eng_45.iloc[:,8:].columns.to_series()[np.isinf(eng_45.iloc[:,8:]).any()]\n\n# Step 2: Drop those columns\neng_45.drop(columns=cols_with_inf, inplace=True)\neng_45.dropna(inplace=True)\n\nX = eng_45.iloc[:,list(range(8, len(eng_45.columns)-1))]\ny = eng_45.iloc[:,len(eng_45.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=3, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\neng_45['tsne1'] = tsne_results[:, 0]\neng_45['tsne2'] = tsne_results[:, 1]\neng_45['tsne3'] = tsne_results[:, 2]\n\n\n\n\n3D t-SNE Plot\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    eng_45,\n    x='tsne1',\n    y='tsne2',\n    z='tsne3',\n    color='scenario',\n    title='&lt;b&gt;3D t-SNE For All Scenarios&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2', 'tsne3': 't-SNE3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'Location_ID': True, 'year': True}\n    \n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='t-SNE1'),\n        yaxis=dict(title='t-SNE2'),\n        zaxis=dict(title='t-SNE3'),\n                camera=dict(\n            eye=dict(x=0.2, y=0, z=-2)\n                )\n    )\n)\nfig.show()\n\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    eng_45[eng_45['scenario'].isin(['sc37','sc40'])],\n    x='tsne1',\n    y='tsne2',\n    z='tsne3',\n    color='scenario',\n    title='&lt;b&gt;3D t-SNE For Scenario 37 and 40&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2', 'tsne3': 't-SNE3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'Location_ID': True, 'year': True}\n    \n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='t-SNE1'),\n        yaxis=dict(title='t-SNE2'),\n        zaxis=dict(title='t-SNE3'),\n                camera=dict(\n            eye=dict(x=0.2, y=0, z=-2)\n                )\n    )\n)\nfig.show()"
  },
  {
    "objectID": "Analysis_45.html#pca",
    "href": "Analysis_45.html#pca",
    "title": "RCP 4.5 Analysis",
    "section": "PCA",
    "text": "PCA\nLets try using another dimensinality reduction technique PCA to see if we can define the two scenarios (37 and 40) within RCP4.5.\nWhat is PCA? Principal Component Analysis (PCA) is a statistical technique used to reduce the dimensionality of a dataset while preserving as much variance as possible. It transforms the original variables into a new set of uncorrelated variables called principal components, which are ordered by the amount of variance they capture from the data. The first principal component captures the most variance, followed by the second, and so on. PCA is widely used in data analysis and machine learning for feature reduction, noise reduction, and visualization of high-dimensional data. By simplifying the dataset, PCA can help improve the performance of algorithms and make data more interpretable.\nWhat will we do with this? We will conduct PCA on each group of RCP to find a pattern in between scenarios and how they group within the reduced dimensionality. Based on how they are grouped and how much each column feature influenced the principal component, we will be able to estimate what features diferentiated different scenarios.\n\n\nPCA(RCP = 4.5)\n# Step 1: Identify columns with inf or -inf\ncols_with_inf = eng_45.iloc[:,8:].columns.to_series()[np.isinf(eng_45.iloc[:,8:]).any()]\n\n# Step 2: Drop those columns\neng_45.drop(columns=cols_with_inf, inplace=True)\neng_45.dropna(inplace=True)\n\nX = eng_45.iloc[:,list(range(8, len(eng_45.columns)-1))]\ny = eng_45.iloc[:,len(eng_45.columns)-3]\n\n\n# data = df_orig[(df_orig['RCP']==4.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\n# X = data.iloc[:,list(range(1, 3))+ [4,6] + list(range(8, len(data.columns)-3))]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Apply PCA\npca = PCA(n_components=10)  # Reduce to 2 components for visualization\nX_pca = pca.fit_transform(X_scaled)\n\n# Add the PCA and cluster results to the DataFrame\neng_45['PCA1'] = X_pca[:, 0]\neng_45['PCA2'] = X_pca[:, 1]\neng_45['PCA3'] = X_pca[:, 2]\n\n# Get the component loadings\nloadings = pca.components_.T\ncolumns = X.columns\n\n# Create a DataFrame for loadings\nloadings_df = pd.DataFrame(loadings, columns=['PCA1', 'PCA2', 'PCA3', 'PCA4', 'PCA5', 'PCA6', 'PCA7', 'PCA8', 'PCA9', 'PCA10'], index=columns)\n\n# Get the explained variance ratio\nexplained_variance_ratio = pca.explained_variance_ratio_\n\n# Cumulative explained variance\ncumulative_explained_variance = np.cumsum(explained_variance_ratio)\n\n\n\nExplained Variance\nWhat is explained variance of PCA? Each principal component has an associated eigenvalue that quantifies how much variance it explains. The explained variance for a principal component is the proportion of the total dataset variance that this component accounts for. If the total variance in the dataset is 100%, the first principal component might explain, for example, 40%, the second 20%, and so on.\nWhat methods can we use to choose how many components we use?\n\nExplained Variance Threshold: Choose the number of components that together explain a sufficiently high percentage of the total variance, such as 95% or 99%. This ensures that most of the variability in the data is retained.\nElbow Method: Plot the explained variance for each principal component and look for an “elbow point,” where the explained variance starts to level off. The number of components at this point is often a good choice.\nScree Plot: Similar to the elbow method, a scree plot shows the eigenvalues associated with each principal component. The point where the eigenvalues drop off sharply (before becoming relatively constant) indicates the optimal number of components.\n\nBy using the elbow method, we can assume that we need principal components 1, 2, 3 and 4. However, since our purpose is to visualize the principle components, we’ll only deal with PCA 1, 2, and 3.\n\n\nVarience Ratio\n# Create a list of x-axis labels from PCA1 to PCA10\nx_labels = [f'PCA{i+1}' for i in range(len(explained_variance_ratio))]\n\n# Create a line chart for explained variance ratio\nfig = go.Figure(data=go.Scatter(\n    x=x_labels,\n    y=explained_variance_ratio,\n    mode='lines+markers',\n    text=explained_variance_ratio,\n    textposition='top center'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Explained Variance Ratio by Principal Components&lt;/b&gt;',\n    xaxis_title='Principal Components',\n    yaxis_title='Explained Variance Ratio',\n    yaxis=dict(tickformat=\".2%\", range=[0, 1.1 * explained_variance_ratio.max()]),  # Adjust the range as needed\n    template='plotly_white',\n    margin=dict(l=50, r=50, b=50, t=50)  # Adjust the padding as needed\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n\nPCA feature importance\nIn order to interpret visualizations made from principle components, we need to understand what features effect each component. Unlike t-SNE where the featur to component calculation changes when we increaes the number of components, the effect that feature has on components stay constant for PCA and therefore, we will plot the feature importance plots in advance to analyze the visualizations that will come later. The following bar graphs are features that influence each component the most ranked by their absolute value and the direction(Positive, Negative) differentiated by color.\n\n\nFeature Importance Plots\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = loadings_df['PCA1'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(20).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(loadings_df.loc[top_features, 'PCA1'],4)\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top 20 Most Influential Features on PCA1&lt;/b&gt;',\n    xaxis_title='Features',\n    xaxis=dict(tickangle=45),\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = loadings_df['PCA2'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(20).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(loadings_df.loc[top_features, 'PCA2'],4)\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top 20 Most Influential Features on PCA2&lt;/b&gt;',\n    xaxis_title='Features',\n    xaxis=dict(tickangle=45),\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings = loadings_df['PCA3'].abs().sort_values(ascending=False)\n\n# Get the top 10 most influential features\ntop_features = sorted_loadings.head(20).index\n\n# Get the actual loadings for these top 10 features\ntop_loadings = round(loadings_df.loc[top_features, 'PCA3'],4)\n\n# Create a color list based on the sign of the loadings\ncolors = ['blue' if val &gt; 0 else 'red' for val in top_loadings]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings.index,\n    y=top_loadings.abs(),\n    text=top_loadings.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top 20 Most Influential Features on PCA3&lt;/b&gt;',\n    xaxis_title='Features',\n    xaxis=dict(tickangle=45),\n    yaxis_title='Absolute PCA1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\n\n                                                \n\n\n\n\n2D PCA\n\n\n2D PCA Plots\n# Visualize the results with Plotly\nfig = px.scatter(\n    eng_45,\n    x='PCA1',\n    y='PCA2',\n    color='scenario',\n    title='&lt;b&gt;PCA For All Scenarios (RCP = 4.5)&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2'},\n    opacity=0.5\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\nfig = px.scatter(\n    eng_45[eng_45['scenario'].isin(['sc37','sc40'])],\n    x='PCA1',\n    y='PCA2',\n    color='scenario',\n    title='&lt;b&gt;PCA for Scenario 37 vs 40 (RCP = 4.5)&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2'},\n    opacity=0.5\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nWhen conducting a 2D PCA analysis for all scenarios, the overall trend indicates that within each scenario, PCA1 primarily influences the data points. In contrast, between different scenarios, PCA2 is the key differentiator.\nWhat does that mean? Similar to our t-SNE analysis, the original features that effect PCA1 are the original features that were not engineered. It makes sense to think that these variables create variance within datapoints within the same scenario.\nAlso similar to the t-SNE, it seems PCA2 consists of engineered features and acts as a component that differentiates different scenarios. Even the highly ranked features that correlate with PCA2 are features with VWC in the denominator and PPT or Transp in the nominator similar to our t-SNE results.\nBut is this the case for scenario 37 and 40? With our plot with only the two scenarios, you could argue that there is a pattern where 37 is in between scenario 40 depending on PCA2 but it does seem a little unclear\nWe’ll add a third component to our analysis to see if we can gain any additional insight.\n\n\n3D PCA\nWhat type of information can we retrieve from the third PCA that we couldn’t from the 2D PCA plot?\n\n\n3D PCA Plots\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    eng_45,\n    x='PCA1',\n    y='PCA2',\n    z='PCA3',\n    color='scenario',\n    title='&lt;b&gt;3D PCA For All Scenarios&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2', 'PCA3': 'PCA3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'year': True}\n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='PCA1'),\n        yaxis=dict(title='PCA2'),\n        zaxis=dict(title='PCA3'),\n                camera=dict(\n            eye=dict(x=2, y=0, z=0.3)\n                )\n    )\n)\nfig.show()\n\nfig = px.scatter_3d(\n    eng_45[eng_45['scenario'].isin(['sc37','sc40'])],\n    x='PCA1',\n    y='PCA2',\n    z='PCA3',\n    color='scenario',\n    title='&lt;b&gt;3D PCA for Scenario 37 vs 40&lt;/b&gt;',\n    labels={'PCA1': 'PCA1', 'PCA2': 'PCA2', 'PCA3': 'PCA3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'year': True}\n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='PCA1'),\n        yaxis=dict(title='PCA2'),\n        zaxis=dict(title='PCA3'),\n                camera=dict(\n            eye=dict(x=2, y=0., z=0.3)\n                )\n    )\n)\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nBy looking at both the plot with all the scenarios and the plot with the two scenarios, we can see that a combination of PCA2 and PCA3 divides the scenarios much better than we could with a single PCA2\nWhat does this mean? When looking at the plot with only the two scenarios, although we do see a clear distinciton, its a little harder to interpret because the two scenarios are not in different quadrants. What makes it even harder to analyze is that scenario 40 is clustered around the center where PCA1 and PCA2 are both equal to one and scenario 37 is scaterred around the center in quadrant 2 and 4. Although the scenarios are divided, its hard to make an analysis of feature relevance to annual temperature."
  },
  {
    "objectID": "Analysis_85.html",
    "href": "Analysis_85.html",
    "title": "RCP 8.5 Analysis",
    "section": "",
    "text": "Now we’ll conduct a more detailed comparison within each RCP scenario(4.5, 8.5) to analyze how the highest temperature scenario and lowest temperature scenario within each group is similar or different.\nMethodology We will use t-SNE with pearson correlation and PCA to visualize these datapoints onto 2D and 3D planes to check if we can visually distinguish between the different scenarios. Then, we will use the original feature’s influence on the generated components to hypothesize what features effect the annual temperature the most.\n\n\nImport module / Set options and theme\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport xml.etree.ElementTree as ET\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom scipy.stats import ttest_rel\nfrom statsmodels.stats.weightstats import ttest_ind\nimport numpy as np\nimport pingouin as pg\nfrom scipy.stats import zscore\nimport plotly.graph_objects as go\nimport pandas as pd\nfrom plotly.subplots import make_subplots\nimport warnings\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport plotly.graph_objects as go\nimport numpy as np\nimport pandas as pd\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport plotly.express as px\nfrom sklearn.manifold import TSNE\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_columns', None)\npd.set_option('display.precision', 10)\n\n\n\n\nImport cleaned data\ndf = pd.read_csv('../data/cleaned_df.csv')\ndf['Location_ID'] = df.groupby(['long', 'lat']).ngroup() + 1\n\ngroup_list = ['Park', 'long', 'lat', 'veg', 'year', 'TimePeriod', 'RCP','treecanopy', 'Ann_Herb', 'Bare', 'Herb', 'Litter', 'Shrub', 'El', 'Sa','Cl', 'RF', 'Slope', 'E', 'S']\nveg_location = df.drop(labels='scenario',axis=1).groupby(group_list).mean().reset_index()\n# veg_location['T_Annual'] = (veg_location['T_Annual'] - veg_location['T_Annual'].min()) / (veg_location['T_Annual'].max() - veg_location['T_Annual'].min())\n\n\n# Average Scenario Dataset\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(veg_location['RCP'], errors='coerce')\n\n# Fill NaNs with original non-numeric values\nveg_location['RCP'] = numeric_series.fillna(veg_location['RCP'])\n\nfour = veg_location[veg_location['RCP'].isin([4.5])]\neight = veg_location[veg_location['RCP'].isin([8.5])]\nfour_h = veg_location[veg_location['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = veg_location[veg_location['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_con = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_con['Location_ID'] = df_con.groupby(['long', 'lat']).ngroup() + 1\n\n\n# Scenario Dataset\n# Convert to numeric, coercing errors to NaN\nnumeric_series = pd.to_numeric(df['RCP'], errors='coerce')\n\nnumeric_series\n\n# Fill NaNs with original non-numeric values\ndf['RCP'] = numeric_series.fillna(df['RCP'])\n\nfour = df[df['RCP'].isin([4.5])]\neight = df[df['RCP'].isin([8.5])]\nfour_h = df[df['RCP'].isin(['historical'])]\nfour_h['RCP'] = 4.5\neight_h = df[df['RCP'].isin(['historical'])]\neight_h['RCP'] = 8.5\n\ndf_orig = pd.concat([four_h, four, eight_h, eight], ignore_index=True)\ndf_orig['Location_ID'] = df_orig.groupby(['long', 'lat']).ngroup() + 1\n\nselected_columns = [col for col in df.columns if not col.startswith(('T_', 'Tmin', 'Tmax'))]\ndropped_columns = [col for col in df.columns if col.startswith(('T_', 'Tmin', 'Tmax'))]\nfiltered_df = df_orig[selected_columns]\nfiltered_df['T_Annual'] = df_orig['T_Annual']\n\ndf_orig = filtered_df"
  },
  {
    "objectID": "Analysis_85.html#t-sne-1st-trial",
    "href": "Analysis_85.html#t-sne-1st-trial",
    "title": "RCP 8.5 Analysis",
    "section": "t-SNE (1st Trial)",
    "text": "t-SNE (1st Trial)\nWhat is t-SNE? t-SNE (t-distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique particularly effective in visualizing high-dimensional data. It works by converting similarities between data points into joint probabilities and minimizing the Kullback-Leibler divergence between these joint probabilities in the high-dimensional and low-dimensional space. This results in a map where similar objects are modeled by nearby points and dissimilar objects by distant points. When interpreting a t-SNE plot, clusters indicate groups of similar data points, suggesting patterns or structures within the data. However, the distances between clusters and the exact positioning can sometimes be arbitrary, so the focus should be on the local neighborhood structures rather than global distances.\nAnalysis Methodology\n\nConduct t-SNE on the dataset to retrieve 2 or 3 newly made components to visualize this onto a 2D or 3D plane. If we see a pattern or grouping of scenarios.\nApply the pearson correlation to analyze which original features correlate to the t-SNE components.\nHypothesize which features effect annual temperature\n\n\n2D Plot\n\n\nt-SNE(RCP = 8.5)\ndata_85 = df_orig[(df_orig['RCP']==8.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\nX = data_85.iloc[:,list(range(1, 3))+ list(range(8, len(data_85.columns)-3))]\ny = data_85.iloc[:,len(data_85.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=2, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\ndata_85['tsne1'] = tsne_results[:, 0]\ndata_85['tsne2'] = tsne_results[:, 1]\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    data_85,\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For All Scenarios (RCP = 8.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    data_85[data_85['scenario'].isin(['sc60','sc58'])],\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For Scenario 60 and 58 (RCP = 8.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nThe analysis demonstrates that t-SNE effectively groups similar data points together, with distinct clusters representing unique scenario and year combinations even when ‘year’ wasn’t part of the input data. This clear grouping contrasts with PCA, which stretched data points across an axis to portray differences within a scenario. In comparing scenarios 60 and 58, the second plot shows that we can distinguish the two scenarios slightly by t-SNE2. Most scenario 60 points are above 15 of t-SNE2 with some exceptions. We can see almost the entire year 2098 of scenario 60 clustered below t-SNE2 = 0.\n\n\nCode\ncorr_matrix = data_85.iloc[:,8:].corr()\n#| code-summary: Correlation Feature Importance\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings_1 = corr_matrix['tsne2'].abs().sort_values(ascending=False)\ntop_features_1 = sorted_loadings_1.head(20).index\ntop_loadings_1 = round(corr_matrix['tsne2'].loc[top_features_1,],4)[1:]\ncolors_1 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_1]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_1.index,\n    y=top_loadings_1.abs(),\n    text=top_loadings_1.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_1,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE2&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\nThis plot highlights the top features that correlate with t-SNE2 to get a better idea of how the scenarios were divided. What was most noticable was that rather than a certain category of varibles such as SWC, WCA, or percipitation, various features of the summer season were highly ranked.\nWhat does this mean? Rather than an absolute value of a feature effecting the temperature, it may be the ratio or the relationship between features. For example it may be the ratio of how much rain there is to how much it evaporates rather than how the rain directly effects temperature. Lets go ahead and perform some feature engineering!\nActions to Take We’ll add all possible ratio for summer related variables and drop the original summer variables to prevent colinearity within our visualizations. Then we’ll re-perform our 2D t-SNE analysis to see if we can get a better result and see which features influenced our visualization."
  },
  {
    "objectID": "Analysis_85.html#feature-engineering",
    "href": "Analysis_85.html#feature-engineering",
    "title": "RCP 8.5 Analysis",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nHere is a snippet of the datset that contain each summer feature combination ratio. This dataset will be merged to the original dataset and the single summer related columns will be dropped to prevent colinearity.\n\n\nCreate summer ratio features\ndata_1 = df_orig[(df_orig['RCP']==8.5) & (df_orig['year'].isin(range(2095,2100)))].dropna(axis=1, how='any')\n\nselected_columns = [col for col in data_1.columns if 'summer' in col.lower()]\ndropped_columns = [col for col in data_1.columns if not 'summer' in col.lower()]\nfiltered_df = data_1[selected_columns]\n\n# Get the list of columns\ncolumns = filtered_df.columns\nratios = {}\n\n# Calculate the ratios\nfor i, col1 in enumerate(columns):\n    for col2 in columns[i+1:]:\n        ratio_col_name = f\"{col1}/{col2}\"\n        ratios[ratio_col_name] = filtered_df[col1] / filtered_df[col2]\n\nratios_df = pd.DataFrame(ratios)\nratios_df.iloc[:,25:].head()\n\n\n\n\n\n\n\n\n\nEvap_Summer/PPT_Summer\nEvap_Summer/SWA_Summer_top50\nEvap_Summer/SWA_Summer_whole\nEvap_Summer/Transp_Summer\nEvap_Summer/VWC_Summer_top50\nEvap_Summer/VWC_Summer_whole\nEvap_Summer/WetSoilDays_Summer_top50\nEvap_Summer/WetSoilDays_Summer_whole\nFrostDays_Summer/PET_Summer\nFrostDays_Summer/PPT_Summer\nFrostDays_Summer/SWA_Summer_top50\nFrostDays_Summer/SWA_Summer_whole\nFrostDays_Summer/Transp_Summer\nFrostDays_Summer/VWC_Summer_top50\nFrostDays_Summer/VWC_Summer_whole\nFrostDays_Summer/WetSoilDays_Summer_top50\nFrostDays_Summer/WetSoilDays_Summer_whole\nPET_Summer/PPT_Summer\nPET_Summer/SWA_Summer_top50\nPET_Summer/SWA_Summer_whole\nPET_Summer/Transp_Summer\nPET_Summer/VWC_Summer_top50\nPET_Summer/VWC_Summer_whole\nPET_Summer/WetSoilDays_Summer_top50\nPET_Summer/WetSoilDays_Summer_whole\nPPT_Summer/SWA_Summer_top50\nPPT_Summer/SWA_Summer_whole\nPPT_Summer/Transp_Summer\nPPT_Summer/VWC_Summer_top50\nPPT_Summer/VWC_Summer_whole\nPPT_Summer/WetSoilDays_Summer_top50\nPPT_Summer/WetSoilDays_Summer_whole\nSWA_Summer_top50/SWA_Summer_whole\nSWA_Summer_top50/Transp_Summer\nSWA_Summer_top50/VWC_Summer_top50\nSWA_Summer_top50/VWC_Summer_whole\nSWA_Summer_top50/WetSoilDays_Summer_top50\nSWA_Summer_top50/WetSoilDays_Summer_whole\nSWA_Summer_whole/Transp_Summer\nSWA_Summer_whole/VWC_Summer_top50\nSWA_Summer_whole/VWC_Summer_whole\nSWA_Summer_whole/WetSoilDays_Summer_top50\nSWA_Summer_whole/WetSoilDays_Summer_whole\nTransp_Summer/VWC_Summer_top50\nTransp_Summer/VWC_Summer_whole\nTransp_Summer/WetSoilDays_Summer_top50\nTransp_Summer/WetSoilDays_Summer_whole\nVWC_Summer_top50/VWC_Summer_whole\nVWC_Summer_top50/WetSoilDays_Summer_top50\nVWC_Summer_top50/WetSoilDays_Summer_whole\nVWC_Summer_whole/WetSoilDays_Summer_top50\nVWC_Summer_whole/WetSoilDays_Summer_whole\nWetSoilDays_Summer_top50/WetSoilDays_Summer_whole\n\n\n\n\n188834\n0.6664161996\n1159.9587759648\n1159.9587759648\n1.9976439220\n87.0074625128\n87.0074625128\n0.6086601289\n0.6086601289\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n9.6463788375\n16790.4108513249\n16790.4108513249\n28.9159088061\n1259.4335876336\n1259.4335876336\n8.8103593382\n8.8103593382\n1740.5921055157\n1740.5921055157\n2.9975920802\n130.5602453369\n130.5602453369\n0.9133333333\n0.9133333333\n1.0\n0.0017221680\n0.0750090989\n0.0750090989\n0.0005247257\n0.0005247257\n0.0017221680\n0.0750090989\n0.0750090989\n0.0005247257\n0.0005247257\n43.5550407936\n43.5550407936\n0.3046890000\n0.3046890000\n1.0\n0.0069954934\n0.0069954934\n0.0069954934\n0.0069954934\n1.0\n\n\n188835\n0.5892222576\n90.4920800105\n90.4920800105\n1.4456365189\n76.2183785743\n76.2183785743\n0.2946111288\n0.2946111288\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n9.4429645768\n1450.2396931332\n1450.2396931332\n23.1679884181\n1221.4872057523\n1221.4872057523\n4.7214822884\n4.7214822884\n153.5788555949\n153.5788555949\n2.4534655647\n129.3542081847\n129.3542081847\n0.5000000000\n0.5000000000\n1.0\n0.0159752822\n0.8422657382\n0.8422657382\n0.0032556565\n0.0032556565\n0.0159752822\n0.8422657382\n0.8422657382\n0.0032556565\n0.0032556565\n52.7230583730\n52.7230583730\n0.2037933636\n0.2037933636\n1.0\n0.0038653555\n0.0038653555\n0.0038653555\n0.0038653555\n1.0\n\n\n188836\n0.3588396412\n5.1728025837\n5.1728025837\n0.7235019429\n75.5322052091\n75.5322052091\n0.1322429619\n0.1322429619\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n4.1113125911\n59.2660507723\n59.2660507723\n8.2893368121\n865.3907502576\n865.3907502576\n1.5151396108\n1.5151396108\n14.4153599270\n14.4153599270\n2.0162263580\n210.4901369311\n210.4901369311\n0.3685294118\n0.3685294118\n1.0\n0.1398665291\n14.6017954458\n14.6017954458\n0.0255650510\n0.0255650510\n0.1398665291\n14.6017954458\n14.6017954458\n0.0255650510\n0.0255650510\n104.3980682497\n104.3980682497\n0.1827817647\n0.1827817647\n1.0\n0.0017508156\n0.0017508156\n0.0017508156\n0.0017508156\n1.0\n\n\n188837\n0.3135721543\n5.2032287767\n5.2032287767\n0.5656431455\n73.1159967227\n73.1159967227\n0.1034788109\n0.1034788109\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n3.8276557910\n63.5138308229\n63.5138308229\n6.9045903216\n892.4991088483\n892.4991088483\n1.2631264110\n1.2631264110\n16.5934018866\n16.5934018866\n1.8038691823\n233.1712038889\n233.1712038889\n0.3300000000\n0.3300000000\n1.0\n0.1087100279\n14.0520434256\n14.0520434256\n0.0198874229\n0.0198874229\n0.1087100279\n14.0520434256\n14.0520434256\n0.0198874229\n0.0198874229\n129.2617037764\n129.2617037764\n0.1829400952\n0.1829400952\n1.0\n0.0014152691\n0.0014152691\n0.0014152691\n0.0014152691\n1.0\n\n\n188838\n0.7620921659\n9830.9524790999\n9830.9524790999\n3.0930312831\n60.4491129300\n60.4491129300\n1.2536416129\n1.2536416129\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n16.1044414370\n207746.5240550612\n207746.5240550612\n65.3615709390\n1277.4034988084\n1277.4034988084\n26.4918061639\n26.4918061639\n12899.9521571569\n12899.9521571569\n4.0586052733\n79.3199505742\n79.3199505742\n1.6450000000\n1.6450000000\n1.0\n0.0003146217\n0.0061488562\n0.0061488562\n0.0001275199\n0.0001275199\n0.0003146217\n0.0061488562\n0.0061488562\n0.0001275199\n0.0001275199\n19.5436474439\n19.5436474439\n0.4053116500\n0.4053116500\n1.0\n0.0207387925\n0.0207387925\n0.0207387925\n0.0207387925\n1.0"
  },
  {
    "objectID": "Analysis_85.html#t-sne-2nd-trial",
    "href": "Analysis_85.html#t-sne-2nd-trial",
    "title": "RCP 8.5 Analysis",
    "section": "t-SNE (2nd Trial)",
    "text": "t-SNE (2nd Trial)\nThis time we’ll drop the original summer related features and replace them with the engineered features and perform t-SNE one more time to see if we can better define the scenarios.\n\n2D t-SNE\n\n\nt-SNE(RCP = 8.5)\neng_85 = pd.concat([data_1[dropped_columns], ratios_df], axis=1)\n\n\n# Step 1: Identify columns with inf or -inf\ncols_with_inf = eng_85.iloc[:,8:].columns.to_series()[np.isinf(eng_85.iloc[:,8:]).any()]\n\n# Step 2: Drop those columns\neng_85.drop(columns=cols_with_inf, inplace=True)\neng_85.dropna(inplace=True)\n\nX = eng_85.iloc[:,list(range(8, len(eng_85.columns)-1))]\ny = eng_85.iloc[:,len(eng_85.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=2, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\neng_85['tsne1'] = tsne_results[:, 0]\neng_85['tsne2'] = tsne_results[:, 1]\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    eng_85,\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For All Scenarios (RCP = 8.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n# Visualize the results with Plotly\nfig = px.scatter(\n    eng_85[eng_85['scenario'].isin(['sc60','sc58'])],\n    x='tsne1',\n    y='tsne2',\n    color='scenario',\n    title='&lt;b&gt;t-SNE For Scenario 60 and 58 (RCP = 8.5)&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2'},\n    opacity=0.5,\n    hover_data={'Location_ID': True, 'year':True}\n)\n\nfig.update_layout(\n    margin=dict(l=10, r=10, b=10, t=40),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nThrough the 2D plot with only scenarios 60 and 58, we can see that t-SNE has become a better indicator for dividing the two scenarios than our earlier dataset without featuere engineering. The higher t-SNE2 is the higher the temperature(scenario 58) and the lower t-SNE2 is the lower the tempearture(scenario 60). t-SNE1 acts like feature that divides points within a scenario. When you examine the scenario 60 points that are above t-SNE2 = 0 you can see that most points in the right upper hand of the plot are from the year 2098, and we’ll look into why this is a bit later.\n\n\nCode\ncorr_matrix = eng_85.iloc[:,8:].corr()\n#| code-summary: Correlation Feature Importance\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings_1 = corr_matrix['tsne1'].abs().sort_values(ascending=False)\ntop_features_1 = sorted_loadings_1.head(20).index\ntop_loadings_1 = round(corr_matrix['tsne1'].loc[top_features_1,],4)[1:]\ncolors_1 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_1]\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings_2 = corr_matrix['tsne2'].abs().sort_values(ascending=False)\ntop_features_2 = sorted_loadings_2.head(20).index\ntop_loadings_2 = round(corr_matrix['tsne2'].loc[top_features_2,],4)[1:]\ncolors_2 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_2]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_1.index,\n    y=top_loadings_1.abs(),\n    text=top_loadings_1.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_1,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE1&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_2.index,\n    y=top_loadings_2.abs(),\n    text=top_loadings_2.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_2,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE2&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE2 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nWhat does this mean? First, lets look at the feature correlations with the t-SNE2 value which divided the two scenarios. The “Top Features Correlating to t-SNE2” plot below shows that most highly ranked features were the ratio features that we added to the dataset. I think its safe to say that it was a successful hypothesis that summer ratio features would matter! Lets interpret the first few features for a sanity check to see if the results make sense logically.\n\nPPT_Summer/VWC_Summer_Whole : This featuer has a negative correlation with t-SNE2 meaning that a higher temperature (higher temperatuer for scenario 58) would occur when this feature is lower. This feature gets lower when there is not much percipitation but large volumetric water in the soil.\nPPT_Summer/VWC_Summer_top50 : The same analysis can be done as the first feature. The difference would be that this feature only looks at the top 50cm instead of the entire soil.\nSWA_Summer_top50/VWC_Summer_whole : This feature also has a negative correlation meaning it has to be low in order for temmperatures to increase(scenario 58). What does it mean when “Soil Water Availability” is low but “Volumetric Water Content” is high? The main difference between the two features is Soil water availability is determined not only by the amount of water present but also by how easily plants can extract it whereas “Volumetric Water Content” only looks at the pure volume of water. This means that soils that are efficient (low volume but high accessibility for plants) have a positive on decreasing the temperature. We’ll dive deeper into all implications in the conclusion.\n\nSecondly, lets take a look at features that correlate with t-SNE1 which acted as a feature to differentiate scenarios. As you can see in the t-SNE1 plot, Other than the top 2 features, all other featuers that were not made from feature engineering and are from the original dataset. This enforces our idea that the t-SNE was used create datapoints within scenarios rather than differentiate between different scenarios.\nLets make a 3D plot to see if we can get a better insight.\n\n\n3D t-SNE\n\n\n3D t-SNE (RCP = 8.5)\n# Step 1: Identify columns with inf or -inf\ncols_with_inf = eng_85.iloc[:,8:].columns.to_series()[np.isinf(eng_85.iloc[:,8:]).any()]\n\n# Step 2: Drop those columns\neng_85.drop(columns=cols_with_inf, inplace=True)\neng_85.dropna(inplace=True)\n\nX = eng_85.iloc[:,list(range(8, len(eng_85.columns)-1))]\ny = eng_85.iloc[:,len(eng_85.columns)-3]\n\n# Standardize the features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\nscaler = StandardScaler()\ny_scaled = pd.Series(scaler.fit_transform(y.values.reshape(-1,1)).flatten())\n\n# Perform t-SNE on the features\ntsne = TSNE(n_components=3, random_state=42)\ntsne_results = tsne.fit_transform(X_scaled)\n\neng_85['tsne1'] = tsne_results[:, 0]\neng_85['tsne2'] = tsne_results[:, 1]\neng_85['tsne3'] = tsne_results[:, 2]\n\n\n\n\n3D t-SNE Plot\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    eng_85,\n    x='tsne1',\n    y='tsne2',\n    z='tsne3',\n    color='scenario',\n    title='&lt;b&gt;3D t-SNE For All Scenarios&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2', 'tsne3': 't-SNE3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'Location_ID': True, 'year': True}\n    \n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='t-SNE1'),\n        yaxis=dict(title='t-SNE2'),\n        zaxis=dict(title='t-SNE3'),\n                camera=dict(\n            eye=dict(x=0.2, y=0, z=-2)\n                )\n    )\n)\nfig.show()\n\n# Visualize the results with Plotly in 3D\nfig = px.scatter_3d(\n    eng_85[eng_85['scenario'].isin(['sc60','sc58'])],\n    x='tsne1',\n    y='tsne2',\n    z='tsne3',\n    color='scenario',\n    title='&lt;b&gt;3D t-SNE For Scenario 60 and 58&lt;/b&gt;',\n    labels={'tsne1': 't-SNE1', 'tsne2': 't-SNE2', 'tsne3': 't-SNE3'},\n    opacity=0.5,\n    size_max=0.1,\n    hover_data={'Location_ID': True, 'year': True}\n    \n)\n\nfig.update_traces(marker=dict(size=3))  # Adjust the size value as needed\n\n\n# Update layout to adjust padding and margins\nfig.update_layout(\n    margin=dict(l=5, r=5, b=5, t=20),  # Adjust the values as needed\n    title_x=0.5,\n    title_y=0.95,\n    scene=dict(\n        xaxis=dict(title='t-SNE1'),\n        yaxis=dict(title='t-SNE2'),\n        zaxis=dict(title='t-SNE3'),\n                camera=dict(\n            eye=dict(x=0.2, y=0, z=-2)\n                )\n    )\n)\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nAlthough t-SNE3 was not a valid feature to divide the scenarios, the depth allowed other t-SNE results to portray the difference better. From the 3D plot showing only scenario 60 and 58, we can see an interesting visual pattern between the two scenarios and you can almost see a circular shape between the two scenarios. But if you examine the points a bit more, you can see that most scenario 60 data points are located on the t-SNE2 &lt; 0 and t-SNE1 &gt; 0 section of the graph. Of course other than our outlier the 2098 year. Lets take a look at the correlation between the original features and t-SNE components on the plots below to dive into details.\n\n\nt-SNE correlation(RCP=8.5)\ncorr_matrix = eng_85.iloc[:,8:].corr()\n#| code-summary: Correlation Feature Importance\n\n# Sort the features by the absolute value of the loading for PCA1\nsorted_loadings_3 = corr_matrix['tsne3'].abs().sort_values(ascending=False)\ntop_features_3 = sorted_loadings_3.head(20).index\ntop_loadings_3 = round(corr_matrix['tsne3'].loc[top_features_3,],4)[1:]\ncolors_3 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_3]\n\nsorted_loadings_2 = corr_matrix['tsne2'].abs().sort_values(ascending=False)\ntop_features_2 = sorted_loadings_2.head(20).index\ntop_loadings_2 = round(corr_matrix['tsne2'].loc[top_features_2,],4)[1:]\ncolors_2 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_2]\n\nsorted_loadings_1 = corr_matrix['tsne1'].abs().sort_values(ascending=False)\ntop_features_1 = sorted_loadings_1.head(20).index\ntop_loadings_1 = round(corr_matrix['tsne1'].loc[top_features_1,],4)[1:]\ncolors_1 = ['blue' if val &gt; 0 else 'red' for val in top_loadings_1]\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_1.index,\n    y=top_loadings_1.abs(),\n    text=top_loadings_1.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_1,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE1&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE1 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n# Create a bar chart\nfig = go.Figure(data=[go.Bar(\n    x=top_loadings_2.index,\n    y=top_loadings_2.abs(),\n    text=top_loadings_2.values,  # Show the actual values as text\n    textposition='inside',\n    marker_color=colors_2,\n    showlegend=False\n)])\n\n# Add legend manually\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='blue'),\n    showlegend=True,\n    name='Positive'\n))\nfig.add_trace(go.Bar(\n    x=[None], y=[None],\n    marker=dict(color='red'),\n    showlegend=True,\n    name='Negative'\n))\n\n# Update layout for better readability\nfig.update_layout(\n    title='&lt;b&gt;Top Features Correlating to t-SNE2&lt;/b&gt;',\n    xaxis_title='Features',\n    yaxis_title='Absolute t-SNE2 Loadings',\n    yaxis=dict(tickformat=\".2f\"),\n    xaxis=dict(\n        tickangle=45,  # Rotate x ticks\n        tickfont=dict(size=10)  # Make the font smaller\n    ),\n    template='plotly_white',\n    legend=dict(\n        orientation=\"h\",\n        yanchor=\"bottom\",\n        y=1.02,\n        xanchor=\"right\",\n        x=1\n    ),\n    margin=dict(l=20, r=20, b=20, t=60)\n)\n\nfig.show()\n\n\n\n                                                \n\n\n\n                                                \n\n\nSo how does our 3D t-SNE differ with the 2D t-SNE?\nSimilarities The correlation between the original featuers and t-SNE features portray a similar pattern.\n\nt-SNE1 is highly correlated with feature groups such as VWC, SWA, WetSoilDays that are not features that were engineered, but were used to differentiate data points within a scenario.\nt-SNE2 has a negative correlation with the engineered features that are ratios of the summer features.\n\nDifferences The main difference is the features that correlate with t-SNE2. Although for both t-SNE models t-SNE2 was the main component that separated the two scenarios, and was componsed of engineered features, the engineered featuers that were highly ranked had slight differences. Here are a few features that are only in this t-SNE2’s components.\n\nTransp_Summer/VWC_Summer_whole : This feature has a negative correlation meaning that this value has to be low for the higher temperature scenarios. This means Transpiration must be low and volume of water needs to be high. In meaning it has a similar definition with the SWA_Summer_top50/VWC_Summer_whole variable.\nPPT Annual : Also, places with less percipitation had a higher temperature.\n\n\n\nConclusion\nBy conducting feature engineering and applying it to 2D and 3D t-SNE models, we see a pattern that “summer ratio” features have a high correlation with a t-SNE component that is able to differentiate the scenario with the highest temperature and the lowest temperature. What we can do with these insights will be discussed further in the future steps secion."
  },
  {
    "objectID": "Analysis_85.html#question-what-was-special-about-2098",
    "href": "Analysis_85.html#question-what-was-special-about-2098",
    "title": "RCP 8.5 Analysis",
    "section": "Question : What was special about 2098?",
    "text": "Question : What was special about 2098?\nAs we saw in the visualizations with t-SNE, we’ve noticed that 2098 of scenario 60 keeps acting like an outlier. Why is this? Is there a problem in the logic or are the datapoints actual outliers.\nThe answer is that for some reason the datapoints of 2098 really are outliers within the timeseries data of scenario 60. Not only is the temperature higher than its past or future values, its features almost look like its from a different scenario. A lineplot with a few variables plotted out will help your understanding.\n\n\nFind maximum, minimum 2098 features\ntemp = eng_85.iloc[:,[4,7] + list(range(8,(len(data_1.columns))))]\ntemp = temp[temp['scenario'].isin(['sc60'])]\n\ntemp = temp.groupby(['year','scenario']).mean().reset_index()\n\n# Find the row corresponding to the year 2098\nrow_2098 = temp[temp['year'] == 2098].iloc[0]\n\ndef is_constant(column):\n    return len(column.unique()) == 1\n\n# Find columns where the value for the year 2098 is the maximum or minimum in the column\nmax_cols = [col for col in temp.columns if not is_constant(temp[col]) and temp[col].max() == row_2098[col]]\nmin_cols = [col for col in temp.columns if not is_constant(temp[col]) and temp[col].min() == row_2098[col]]\n\n\n\n\nPlot 2098 difference\n# List of features to be plotted\nfeatures = [\n    \"T_Annual\",\n    \"DrySoilDays_Spring_top50\",\n    \"DrySoilDays_Summer_top50/Evap_Summer\",\n    \"SWA_Spring_whole\"\n]\n\n# Create the 2x2 subplot layout\nfig = make_subplots(rows=2, cols=2, \n                    subplot_titles=[f\"&lt;b&gt;{feature}&lt;/b&gt;\" for feature in features],\n                    horizontal_spacing=0.2,\n                    vertical_spacing=0.2\n                    )\n\n# Add bar charts for each feature to the subplots\nfor i, feature in enumerate(features):\n    fig.add_trace(\n        go.Line(\n            x=temp['year'],\n            y=temp[feature],\n            text=[round(val, 2) for val in temp[feature]],  # Show the actual values as text\n            # textposition='inside',\n            showlegend=False,\n            name=feature\n        ),\n        row=(i//2) + 1, col=(i%2) + 1\n    )\n\n    # Update x and y axis titles for each subplot\n    fig.update_xaxes(title_text='Year', row=(i//2) + 1, col=(i%2) + 1)\n    fig.update_yaxes(title_text=feature, tickformat=\".2f\", row=(i//2) + 1, col=(i%2) + 1)\n\n# Update layout for better readability and center the main title\nfig.update_layout(\n    title={\n        'text': \"&lt;b&gt;2095~2099 Values for Different Features for Scenario 60&lt;/b&gt;\",\n        'x': 0.5,  # Center the title\n        'y': 0.99,\n        'xanchor': 'center',\n        'yanchor': 'top',\n        'font': {'size': 18}\n    },\n    template='plotly_white',\n    margin=dict(l=20, r=20, b=20, t=60),\n    height=700\n)\n\n# Update subplot title font sizes\nfor annotation in fig['layout']['annotations']:\n    annotation['font'] = dict(size=12)  # Subplot title font size\n\nfig.show()\n\n\nC:\\Users\\JaeHoBahng\\anaconda3\\envs\\dsan5200\\Lib\\site-packages\\plotly\\graph_objs\\_deprecations.py:378: DeprecationWarning:\n\nplotly.graph_objs.Line is deprecated.\nPlease replace it with one of the following more specific types\n  - plotly.graph_objs.scatter.Line\n  - plotly.graph_objs.layout.shape.Line\n  - etc."
  },
  {
    "objectID": "Conclusion.html",
    "href": "Conclusion.html",
    "title": "Conclusion / Future Actions",
    "section": "",
    "text": "For RCP 8.5, we were able to find logical correlations between the highest and lowest temperature scenarios for RCP8.5 by conducting feature engineering and creating ratios between all combination of “summer” related features, and we were also able to hypothesize which features created variance within scenarios.\nThe top features that created a difference between scenarios were the engineered ratio features. For example, the feature PPT_Summer/VWC_Summer_Whole negatively correlated with t-SNE2, meaning higher precipitation and lower volumetric water content in the soil led to higher temperatures.\nOn the other hand, features that generated points within a scenario were the original feature such as VWC, SWA, WetSoilDays and more.\nIn conclusion, the feature engineering and application to 2D and 3D t-SNE models demonstrated that “summer ratio” features highly correlate with a t-SNE component that differentiates the scenarios with the highest and lowest temperatures.\n\n\n\nAlthough the overall trend of which features influenced scenario data generation and scenario differentiation were similar, the degree in which the visualizations were interpretable were different from RCP8.5. The visualizations gave us enough information to hypothesize what features effected the scenario differentiation, but didn’t give us enough to predict which original features effected the annual temperature.\n\n\n\nOne theory is that since RCP8.5 had a steeper increase in annual temperature compared to RCP4.5, the difference between scenarios are more evident thus making it easier to differentiate through visualizations. The temperature difference between highest and lowest scenario is grater for RCP8.5 as shown in the EDA secsion as the difference for the RCP4.5 scenarios is 2.5 whereas the difference is 3.5 for RCP8.5. Furthermore, the variance within each scenerio is greater for RCP8.5 than 4.5."
  },
  {
    "objectID": "Conclusion.html#rcp-8.5",
    "href": "Conclusion.html#rcp-8.5",
    "title": "Conclusion / Future Actions",
    "section": "",
    "text": "For RCP 8.5, we were able to find logical correlations between the highest and lowest temperature scenarios for RCP8.5 by conducting feature engineering and creating ratios between all combination of “summer” related features, and we were also able to hypothesize which features created variance within scenarios.\nThe top features that created a difference between scenarios were the engineered ratio features. For example, the feature PPT_Summer/VWC_Summer_Whole negatively correlated with t-SNE2, meaning higher precipitation and lower volumetric water content in the soil led to higher temperatures.\nOn the other hand, features that generated points within a scenario were the original feature such as VWC, SWA, WetSoilDays and more.\nIn conclusion, the feature engineering and application to 2D and 3D t-SNE models demonstrated that “summer ratio” features highly correlate with a t-SNE component that differentiates the scenarios with the highest and lowest temperatures."
  },
  {
    "objectID": "Conclusion.html#rcp-4.5",
    "href": "Conclusion.html#rcp-4.5",
    "title": "Conclusion / Future Actions",
    "section": "",
    "text": "Although the overall trend of which features influenced scenario data generation and scenario differentiation were similar, the degree in which the visualizations were interpretable were different from RCP8.5. The visualizations gave us enough information to hypothesize what features effected the scenario differentiation, but didn’t give us enough to predict which original features effected the annual temperature."
  },
  {
    "objectID": "Conclusion.html#why-are-the-results-different",
    "href": "Conclusion.html#why-are-the-results-different",
    "title": "Conclusion / Future Actions",
    "section": "",
    "text": "One theory is that since RCP8.5 had a steeper increase in annual temperature compared to RCP4.5, the difference between scenarios are more evident thus making it easier to differentiate through visualizations. The temperature difference between highest and lowest scenario is grater for RCP8.5 as shown in the EDA secsion as the difference for the RCP4.5 scenarios is 2.5 whereas the difference is 3.5 for RCP8.5. Furthermore, the variance within each scenerio is greater for RCP8.5 than 4.5."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Natural Bridges National Monument Preservation",
    "section": "",
    "text": "Natural Bridges National Monument\n\n\n\nhttps://cdn.britannica.com/08/117908-050-D75717AE/Owachomo-Bridge-Natural-Bridges-National-Monument-Utah.jpg\n\n\n\nWhat is the Natural Bridges National Monument?1\n\nVisit the Official Website!\nBrief Description\nNatural Bridges National Monument is situated 43 miles west of Blanding in San Juan County, Utah, encompassing 7,636.88 acres. The county, the largest in Utah, spans 7,884 square miles within the Colorado Plateau, with elevations ranging from 4,200 to 10,000 feet and receiving only 13 inches of annual precipitation. The park’s landscape includes desert canyons and forested mountains.\nHistorically, the area was first inhabited during the Archaic period (7000 BC to AD 500) by hunter-gatherers, with later occupations by the ancestors of the Puebloan people for farming around AD 700. Subsequent migrations included those from Mesa Verde in the 1200s. By the 1300s, Ancestral Puebloans moved south, followed by Navajos and Paiutes. The site’s significance grew after prospector Cass Hite discovered the bridges in 1883, leading to its establishment as Utah’s first national monument in 1908 by President Theodore Roosevelt. The park features three major natural bridges—Sipapu, Kachina, and Owachomo—each representing different stages of geological development, with names reflecting the region’s Puebloan heritage and culture.\nWhy is it unique?\nNatural Bridges National Monument is unique for having three large natural bridges in close proximity. It also contains significant prehistoric structures and archeological sites with well-preserved wooden features, offering valuable insights into Ancestral Puebloan history on the Colorado Plateau. The park is internationally recognized for its exceptional night sky, being the first designated International Dark Sky Park. Additionally, its deep, moist canyons and diverse ecosystems have been preserved in their natural state due to a long history of protection.\n\n\n\n\nReferences\n\n1. National Park Service. Foundation document. Natural Bridges National Monument (2018)."
  }
]